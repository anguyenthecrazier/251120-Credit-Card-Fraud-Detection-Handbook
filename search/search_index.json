{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Credit Card Fraud Detection Handbook","text":"<p>Welcome to the Credit Card Fraud Detection Handbook \u2014 A complete end-to-end analysis for building a hybrid machine-learning credit card fraud detection system by Group 6 - Queen Mary University of London MSc Risk Analytics - November 2025</p> <p>This site contains:</p> <ul> <li>\ud83d\udcca Full EDA  </li> <li>\ud83e\udde0 Machine Learning Models  </li> <li>\ud83d\udcc1 Fully reproducible notebooks  </li> <li>\ud83d\udcbb Interactive demo  </li> </ul> <p>Use the bar navigation to explore the project.</p>"},{"location":"demo/","title":"Interactive Fraud Detection Demo","text":"<p>Welcome to the Interactive Fraud Detection Demo for the Credit Card Fraud Detection \u2013 MSc Risk Analytics PLA (Group 6).</p> <p>This page turns our technical work into a story:</p> <ul> <li>See the imbalance problem in the dataset  </li> <li>Understand the key EDA insights that drive model design  </li> <li>Compare unsupervised, supervised, and the final Hybrid model </li> <li>See how a single transaction is turned into a fraud probability  </li> </ul> <p>This page is static \u2013 it shows results exported from our notebooks, it does not run Python in the browser.</p>"},{"location":"demo/#1-dataset-imbalance","title":"1. Dataset &amp; Imbalance","text":"<p>We use the classic Credit Card Fraud Detection dataset (284,807 transactions over 2 days, European cardholders).</p> Item Value Total transactions 284,807 Fraudulent transactions 492 Fraud rate ~0.172% Features 30 (<code>Time</code>, <code>Amount</code>, PCA components <code>V1\u2013V28</code>) Target <code>Class</code> (0 = legitimate, 1 = fraud) <p>!!! warning \"Severe class imbalance\"     Only 0.172% of transactions are fraudulent.     A model that predicts \u201ceverything is normal\u201d gets 99.8% accuracy     but misses all real frauds \u2192 we care about recall and F1, not accuracy.</p>"},{"location":"demo/#2-what-eda-told-us","title":"2. What EDA Told Us","text":"<p>From the EDA notebook we learned:</p> <ul> <li>Fraud amounts</li> </ul> <p>Fraudulent transactions are usually small \u201ctesting\u201d amounts, with a few large outliers where the card is fully exploited.</p> <ul> <li>Time-of-day pattern</li> </ul> <p>Fraud is more likely around ~02:00 AM when normal activity is low,   but still appears during the day \u2192 fraud is not only a \u201cnight-time\u201d event.</p> <ul> <li>Only 11 truly informative features</li> </ul> <p>Out of 30 features, only 11 have <code>|corr(Class)| \u2265 0.1</code>, and none above 0.5.   \u2192 Fraud patterns are non-linear and multivariate, not visible in simple correlations.</p> <ul> <li>Highly skewed, heavy-tailed features</li> </ul> <p>Many variables are skewed and fraud often lies in the tails.   This motivated log-transformations (for anomaly detection) and tree-based methods (for supervised learning).</p> <ul> <li>Multivariate regression confirms weak linear separability</li> </ul> <p>Logistic Regression achieves an excellent ranking capability (ROC-AUC \u2248 0.97), but precision remains poor at standard thresholds because fraud is rare and often subtle.   \u2192 Linear models recognize some patterns but cannot separate fraud cleanly, motivating more advanced, non-linear models.</p> <p>\ud83d\udd17 Full details in the EDA notebook: <code>../notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/</code></p>"},{"location":"demo/#3-models-key-results","title":"3. Models &amp; Key Results","text":"<p>We evaluate three categories:</p> <ul> <li>Unsupervised anomaly detection </li> <li>Supervised machine learning (with SMOTE) </li> <li>A final Hybrid meta-model combining all signals</li> </ul> <p>All performance numbers below are evaluated on the full original dataset (no SMOTE used in evaluation).</p>"},{"location":"demo/#31-unsupervised-models-anomaly-detection","title":"3.1 Unsupervised Models \u2014 Anomaly Detection","text":"<p>From all tested methods, two consistently performed best:</p>"},{"location":"demo/#chosen-unsupervised-models","title":"Chosen Unsupervised Models","text":"<ul> <li>Isolation Forest</li> <li>Autoencoder</li> </ul>"},{"location":"demo/#performance","title":"Performance","text":"Method Precision (1) Recall (1) F1-score (1) Accuracy Isolation Forest (Full) 0.0294 0.9514 0.0569 0.9512 Autoencoder (Full) 0.0154 0.9014 0.0304 0.9014 Isolation Forest (High-Corr) 0.0310 0.9515 0.0599 0.9514 Autoencoder (High-Corr) 0.0157 0.9014 0.0309 0.9014 <p>!!! info \"Interpretation\"     - High recall \u2192 they catch most frauds     - Low precision (typical for anomaly detectors)     - Their scores become powerful Hybrid model inputs</p>"},{"location":"demo/#32-supervised-models-learning-from-labels-with-smote","title":"3.2 Supervised Models \u2014 Learning From Labels (with SMOTE)","text":"<p>Supervised models were trained on SMOTE-balanced data and evaluated on the full dataset.</p>"},{"location":"demo/#all-supervised-models-tested","title":"All Supervised Models Tested","text":"Model Precision (1) Recall (1) F1-score (1) Accuracy Notes Random Forest 0.9389 0.9999 0.9685 0.9999 Kept for Hybrid XGBoost 0.8723 0.9999 0.9318 0.9997 Kept for Hybrid CatBoost 0.8586 0.9997 0.9239 0.9997 Kept for Hybrid AdaBoost 0.0902 0.8951 0.1639 0.8950 Excluded LightGBM 0.0094 1.0000 0.0186 0.8735 Excluded <p>!!! failure \"Why not AdaBoost or LightGBM?\"     - AdaBoost: precision only 0.09 \u2192 too many false alarms     - LightGBM: precision 0.009 despite perfect recall     \u2192 Both unsuitable for real-world use</p>"},{"location":"demo/#33-hybrid-meta-model-final-system","title":"3.3 Hybrid Meta-Model \u2014 Final System","text":"<p>The Hybrid model combines unsupervised anomaly scores and supervised predicted probabilities, using:</p>"},{"location":"demo/#inputs","title":"Inputs","text":"<p>Unsupervised signals - Isolation Forest score (<code>iso_score</code>) - Autoencoder reconstruction error (<code>ae_mse</code>)</p> <p>Supervised signals - Random Forest (<code>rf_pred</code>) - XGBoost (<code>xgb_pred</code>) - CatBoost (<code>cat_pred</code>)</p>"},{"location":"demo/#meta-classifier","title":"Meta-classifier","text":"<ul> <li>Logistic Regression</li> <li>Threshold optimized for max F1</li> <li>~0.61 (Full data)</li> <li>~0.597 (High-Corr)</li> </ul>"},{"location":"demo/#hybrid-performance","title":"Hybrid Performance","text":"Metric Value Precision (1) 0.9609 Recall (1) 1.0000 F1-score (1) 0.9801 Accuracy 0.9999 False Positives 20 False Negatives 0 <p>!!! success \"Why Hybrid Wins\"     - Perfect recall     - Best precision     - Lowest false positives     - Integrates structural anomaly signals + supervised evidence</p>"},{"location":"demo/#4-how-the-data-models-flow-pipeline","title":"4. How the Data &amp; Models Flow (Pipeline)","text":"<p>This section follows the same logic used in the Models notebook and the predictive-models poster.</p> <pre><code>RAW DATA\n(Time, Amount, V1\u2013V28, Class = 0/1, heavily imbalanced)\n\n        \u2193\n\nPREPROCESSING\n- Log transform skewed features\n- MinMaxScaler (for anomaly detection branch)\n- SMOTE (for supervised learning branch)\n\n        \u2193\n\nUNSUPERVISED LEARNING               SUPERVISED LEARNING\n- Isolation Forest (full +          - Random Forest\n  high-correlation datasets)        - XGBoost\n- Autoencoder (full +               - CatBoost\n  high-correlation datasets)\n\n        \u2193\n\nHYBRID META-MODEL (Logistic Regression)\n- Inputs = unsupervised scores + supervised probabilities\n\n        \u2193\n\nFINAL FRAUD PROBABILITY\n(Optimised decision threshold \u2248 0.60)\n</code></pre>"},{"location":"demo/#unsupervised-branch","title":"Unsupervised Branch","text":"<ul> <li>Log-transform highly skewed features </li> <li> <p>For each feature (except <code>Class</code>), if |skew| &gt; 0.75, apply a custom log transform.</p> </li> <li> <p>MinMax scaling </p> </li> <li> <p>Scale all features (<code>Time</code>, <code>Amount</code>, <code>V1\u2013V28</code>) into a common range \u2192 <code>X_scaled</code>.</p> </li> <li> <p>Train anomaly detectors on the full scaled data </p> </li> <li> <p>Fit and evaluate on <code>X_scaled</code>, <code>y</code> using:  </p> <ul> <li>Isolation Forest  </li> <li>One-Class SVM  </li> <li>Local Outlier Factor (LOF)  </li> <li>Autoencoder</li> </ul> </li> <li> <p>High-correlation subset for improved anomaly detection </p> </li> <li>Select only the 11 features with |corr(<code>Class</code>)| \u2265 0.1.  </li> <li>Repeat the anomaly-detection experiments on this reduced feature set to see if performance improves.</li> </ul>"},{"location":"demo/#supervised-branch","title":"Supervised Branch","text":"<ul> <li>Original feature space </li> <li> <p>Use the original features (no MinMax scaling) for supervised learning.</p> </li> <li> <p>SMOTE oversampling </p> </li> <li> <p>Apply SMOTE to the full 30-feature dataset     \u2192 balanced training data: <code>X_res</code>, <code>y_res</code>.</p> </li> <li> <p>Train\u2013test split on the SMOTE data </p> </li> <li> <p>Split into <code>X_train</code>, <code>X_test</code>, <code>y_train</code>, <code>y_test</code>.</p> </li> <li> <p>Train supervised models </p> </li> <li>Random Forest  </li> <li>XGBoost  </li> <li>CatBoost  </li> <li>AdaBoost  </li> <li> <p>LightGBM</p> </li> <li> <p>Evaluate on the full original dataset </p> </li> <li>Use the models trained on SMOTE data to predict on the full imbalanced dataset (<code>df</code>)  </li> <li>This mimics real-world deployment, where fraud is rare.</li> </ul>"},{"location":"demo/#hybrid-model","title":"Hybrid Model","text":"<ul> <li>Inputs from the Unsupervised Branch (on scaled data) </li> <li><code>iso_score</code> = Isolation Forest anomaly score on <code>X_scaled</code> </li> <li><code>ae_mse</code>   = Autoencoder reconstruction error on <code>X_scaled</code> </li> <li> <p>(For the second hybrid variant, the same scores are computed on the 11-feature high-correlation subset.)</p> </li> <li> <p>Inputs from the Supervised Branch (trained on SMOTE, predicted on full data) </p> </li> <li><code>rf_pred</code>  = Random Forest P(<code>Class</code> = 1)  </li> <li><code>xgb_pred</code> = XGBoost P(<code>Class</code> = 1)  </li> <li> <p><code>cat_pred</code> = CatBoost P(<code>Class</code> = 1)</p> </li> <li> <p>Build the hybrid feature set </p> </li> <li> <p>Stack these features:  </p> <ul> <li><code>[iso_score, ae_mse, rf_pred, xgb_pred, cat_pred]</code></li> </ul> </li> <li> <p>Meta-classifier: Logistic Regression </p> </li> <li>Train a Logistic Regression model on the full dataset using the stacked features.  </li> <li> <p>Choose a decision threshold \u2248 0.60 to maximise the F1-score.</p> </li> <li> <p>Final output </p> </li> <li>Final fraud probability and a fraud / non-fraud decision.  </li> <li>In the best configuration, the hybrid model achieves 0 false negatives and only 20 false positives.</li> </ul>"},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/","title":"Exploratory Data Analysis (EDA)","text":"In\u00a0[26]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nstyle.use('ggplot')\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n%matplotlib inline\npd.options.mode.chained_assignment = None\nimport matplotlib.font_manager\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom typing import Dict, List\nfrom sklearn import ensemble\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport plotly.figure_factory as ff\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib.style as style style.use('ggplot') import matplotlib.gridspec as gridspec import seaborn as sns sns.set_style(\"darkgrid\") %matplotlib inline pd.options.mode.chained_assignment = None import matplotlib.font_manager from scipy.stats import norm from scipy import stats from sklearn.model_selection import train_test_split from sklearn.model_selection import GridSearchCV from sklearn.model_selection import cross_val_score from sklearn.pipeline import Pipeline, make_pipeline from sklearn.preprocessing import StandardScaler, PolynomialFeatures from sklearn.ensemble import IsolationForest from sklearn.linear_model import LinearRegression from sklearn.linear_model import LogisticRegression from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc from sklearn.tree import DecisionTreeRegressor from sklearn.ensemble import RandomForestRegressor from sklearn.cluster import DBSCAN from sklearn.neighbors import LocalOutlierFactor from sklearn.svm import OneClassSVM from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score from typing import Dict, List from sklearn import ensemble import warnings warnings.filterwarnings(\"ignore\") import plotly.figure_factory as ff from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot  In\u00a0[27]: Copied! <pre>!pip install --upgrade statsmodels\nimport statsmodels.api as sm\n</pre> !pip install --upgrade statsmodels import statsmodels.api as sm <pre>Requirement already satisfied: statsmodels in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (0.14.5)\nRequirement already satisfied: patsy&gt;=0.5.6 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (1.0.2)\nRequirement already satisfied: pandas!=2.1.0,&gt;=1.4 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (1.5.3)\nRequirement already satisfied: numpy&lt;3,&gt;=1.22.3 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (1.26.4)\nRequirement already satisfied: scipy!=1.9.2,&gt;=1.8 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (1.10.0)\nRequirement already satisfied: packaging&gt;=21.3 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (22.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2022.7)\nRequirement already satisfied: six&gt;=1.5 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from python-dateutil&gt;=2.8.1-&gt;pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (1.16.0)\n</pre> In\u00a0[28]: Copied! <pre>import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nfrom tensorflow.keras.regularizers import l2\n</pre> import tensorflow as tf from tensorflow.keras.models import Model from tensorflow.keras.layers import Input, Dense, Dropout from tensorflow.keras.regularizers import l2 In\u00a0[29]: Copied! <pre>from sklearn.metrics import precision_recall_curve\n</pre> from sklearn.metrics import precision_recall_curve In\u00a0[30]: Copied! <pre>#Data load\nfile_path = \"/Users/panguyen277/Downloads/creditcard.csv\"\n\ndf = pd.read_csv(file_path)\nprint(df.head())\n</pre> #Data load file_path = \"/Users/panguyen277/Downloads/creditcard.csv\"  df = pd.read_csv(file_path) print(df.head()) <pre>   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]\n</pre> In\u00a0[31]: Copied! <pre>data = df.copy()\n</pre> data = df.copy() In\u00a0[32]: Copied! <pre># Number of observations\nnum_observations = data.shape[0]\nprint(\"Number of observations in the dataframe:\", num_observations)\n</pre> # Number of observations num_observations = data.shape[0] print(\"Number of observations in the dataframe:\", num_observations) <pre>Number of observations in the dataframe: 284807\n</pre> In\u00a0[33]: Copied! <pre># Dimension exploration\nprint(\"Number of rows:\", data.shape[0])\nprint(\"Number of columns:\", data.shape[1])\n</pre> # Dimension exploration print(\"Number of rows:\", data.shape[0]) print(\"Number of columns:\", data.shape[1]) <pre>Number of rows: 284807\nNumber of columns: 31\n</pre> In\u00a0[34]: Copied! <pre>#Structural summary\ndata.info()\n</pre> #Structural summary data.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\n</pre> <p>So most of variables in dataframe is float, while class is integer. Also, there are no missing value in this dataset.</p> In\u00a0[35]: Copied! <pre>data.describe()\n</pre> data.describe() Out[35]: Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class count 284807.000000 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 ... 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 2.848070e+05 284807.000000 284807.000000 mean 94813.859575 1.168375e-15 3.416908e-16 -1.379537e-15 2.074095e-15 9.604066e-16 1.487313e-15 -5.556467e-16 1.213481e-16 -2.406331e-15 ... 1.654067e-16 -3.568593e-16 2.578648e-16 4.473266e-15 5.340915e-16 1.683437e-15 -3.660091e-16 -1.227390e-16 88.349619 0.001727 std 47488.145955 1.958696e+00 1.651309e+00 1.516255e+00 1.415869e+00 1.380247e+00 1.332271e+00 1.237094e+00 1.194353e+00 1.098632e+00 ... 7.345240e-01 7.257016e-01 6.244603e-01 6.056471e-01 5.212781e-01 4.822270e-01 4.036325e-01 3.300833e-01 250.120109 0.041527 min 0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01 ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00 -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01 0.000000 0.000000 25% 54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01 ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01 -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02 5.600000 0.000000 50% 84692.000000 1.810880e-02 6.548556e-02 1.798463e-01 -1.984653e-02 -5.433583e-02 -2.741871e-01 4.010308e-02 2.235804e-02 -5.142873e-02 ... -2.945017e-02 6.781943e-03 -1.119293e-02 4.097606e-02 1.659350e-02 -5.213911e-02 1.342146e-03 1.124383e-02 22.000000 0.000000 75% 139320.500000 1.315642e+00 8.037239e-01 1.027196e+00 7.433413e-01 6.119264e-01 3.985649e-01 5.704361e-01 3.273459e-01 5.971390e-01 ... 1.863772e-01 5.285536e-01 1.476421e-01 4.395266e-01 3.507156e-01 2.409522e-01 9.104512e-02 7.827995e-02 77.165000 0.000000 max 172792.000000 2.454930e+00 2.205773e+01 9.382558e+00 1.687534e+01 3.480167e+01 7.330163e+01 1.205895e+02 2.000721e+01 1.559499e+01 ... 2.720284e+01 1.050309e+01 2.252841e+01 4.584549e+00 7.519589e+00 3.517346e+00 3.161220e+01 3.384781e+01 25691.160000 1.000000 <p>8 rows \u00d7 31 columns</p> <p>The data set contains 284,807 transactions. The mean value of all transactions is 88.35USD while the largest transaction recorded in this data set amounts to 25,691USD. However, as you might be guessing right now based on the mean and maximum, the distribution of the monetary value of all transactions is heavily right-skewed. The vast majority of transactions are relatively small and only a tiny fraction of transactions comes even close to the maximum.</p> <p>'Class' is an important feature in this dataset as it labels whether the transaction is normal transaction (Class 0) or fraud transaction (Class 1). In the EDA part, we first understand variable 'Class', then explore its relationships with other variables, including Amount, Time and other anonymous variables.</p> In\u00a0[36]: Copied! <pre># Number of transactions under each class\ndata['Class'].value_counts()\n</pre> # Number of transactions under each class data['Class'].value_counts() Out[36]: <pre>0    284315\n1       492\nName: Class, dtype: int64</pre> In\u00a0[37]: Copied! <pre># Adjustment for poster format\nplt.figure(figsize=(14, 10))\n\n# Set the graph\nplt.rcParams['font.family'] = 'arial'\n\nax = sns.countplot(x='Class', data=data, palette='pastel', width=0.5, hue='Class')\nax.legend_.remove()\nplt.title('Distribution of Legitimate and Fraudulent Transaction', fontsize=20, weight='bold')\nplt.xlabel('Transaction Class', fontsize=16, labelpad=20)\nplt.ylabel('Count', fontsize=16, labelpad=20)\nplt.xticks([0, 1], ['Legitimate (Class 0)', 'Fraudulent (Class 1)'], fontsize=14)\nplt.yticks(fontsize=12)\n\n# Add count labels on top of each bar\nfor p in ax.patches:\n    height = p.get_height()\n    ax.annotate(f'{int(height)}',\n                (p.get_x() + p.get_width() / 2., height),\n                ha='center', va='bottom', fontsize=12, weight='bold')\n\nplt.show()\n</pre> # Adjustment for poster format plt.figure(figsize=(14, 10))  # Set the graph plt.rcParams['font.family'] = 'arial'  ax = sns.countplot(x='Class', data=data, palette='pastel', width=0.5, hue='Class') ax.legend_.remove() plt.title('Distribution of Legitimate and Fraudulent Transaction', fontsize=20, weight='bold') plt.xlabel('Transaction Class', fontsize=16, labelpad=20) plt.ylabel('Count', fontsize=16, labelpad=20) plt.xticks([0, 1], ['Legitimate (Class 0)', 'Fraudulent (Class 1)'], fontsize=14) plt.yticks(fontsize=12)  # Add count labels on top of each bar for p in ax.patches:     height = p.get_height()     ax.annotate(f'{int(height)}',                 (p.get_x() + p.get_width() / 2., height),                 ha='center', va='bottom', fontsize=12, weight='bold')  plt.show() <p>A comparison of the transaction classes shows that there are 284,315 legitimate transactions (Class 0) and only 492 fraudulent transactions (Class 1). In percentage terms, fraudulent transactions make up only about 0.172% of the entire dataset. This analysis faces the limitations including a strong class imbalance, anonymized data limits interpretability, and the fact that the dataset reflects transactions from a single region and period. Hence, model generalization may be limited.</p> In\u00a0[38]: Copied! <pre>#Comparing Transaction Amounts\n\ndata.groupby('Class')['Amount'].describe()\n</pre> #Comparing Transaction Amounts  data.groupby('Class')['Amount'].describe() Out[38]: count mean std min 25% 50% 75% max Class 0 284315.0 88.291022 250.105092 0.0 5.65 22.00 77.05 25691.16 1 492.0 122.211321 256.683288 0.0 1.00 9.25 105.89 2125.87 <p>The summary shows that the mean of fraudulent transaction amount is higher than that of legitimate one. However, the median of fraudulent transaction amount is approximately 9.25 indicating large discrepancy between the mean and median. This means that most fraudulent transactions involve small amounts, but a few extremely large transactions are pulling the mean upwards.</p> In\u00a0[39]: Copied! <pre># Adjustment for poster format\nplt.figure(figsize=(14, 10))\n\n# Set a default sans-serif font to avoid warnings\nplt.rcParams['font.family'] = 'arial'\nplt.rcParams['font.sans-serif'] = ['arial']\n\n# Setting boxplot by using seaborn\nax = sns.boxplot(\n    x='Class',\n    y='Amount',\n    data=data,\n    palette='pastel',\n    width=0.3,\n    hue='Class',                         \n    boxprops=dict(edgecolor='none'),     \n    whiskerprops=dict(color=\"darkgrey\"),\n    capprops=dict(color='darkgrey'),\n    medianprops=dict(color='lightgrey'),\n    flierprops=dict(\n        markeredgecolor='darkgrey',\n        markerfacecolor='darkgrey',\n        markersize=5\n    )\n)\n\n# Remove legend (since hue duplicates x axis categories)\nif ax.legend_ is not None:\n    ax.legend_.remove()\n\n# changing scale of y-axis to logarithm\nplt.yscale('log')\n\n# Adding title and label\nplt.title('Distribution of Transaction Amount by Class', fontsize=20, weight='bold')\nplt.xlabel('Transaction Class', fontsize=16, labelpad=50)\nplt.ylabel('Transaction Amount (Logarithmic Scale)', fontsize=16, labelpad=50)  # Increased labelpad\n\n# Setting label of x-axis\nplt.xticks([0, 1], ['Legitimate (Class 0)', 'Fraudulent (Class 1)'], fontsize=14)\nplt.yticks(fontsize=12)  # Adjust y-tick font size\n\n# Adding grid for better readability\nplt.grid(axis='y', linestyle='--', alpha=0.7, color='lightgrey')  # Grid line color\n\n# Removing spines for a cleaner look\nsns.despine(left=True, bottom=True)\n\nplt.show()\n</pre> # Adjustment for poster format plt.figure(figsize=(14, 10))  # Set a default sans-serif font to avoid warnings plt.rcParams['font.family'] = 'arial' plt.rcParams['font.sans-serif'] = ['arial']  # Setting boxplot by using seaborn ax = sns.boxplot(     x='Class',     y='Amount',     data=data,     palette='pastel',     width=0.3,     hue='Class',                              boxprops=dict(edgecolor='none'),          whiskerprops=dict(color=\"darkgrey\"),     capprops=dict(color='darkgrey'),     medianprops=dict(color='lightgrey'),     flierprops=dict(         markeredgecolor='darkgrey',         markerfacecolor='darkgrey',         markersize=5     ) )  # Remove legend (since hue duplicates x axis categories) if ax.legend_ is not None:     ax.legend_.remove()  # changing scale of y-axis to logarithm plt.yscale('log')  # Adding title and label plt.title('Distribution of Transaction Amount by Class', fontsize=20, weight='bold') plt.xlabel('Transaction Class', fontsize=16, labelpad=50) plt.ylabel('Transaction Amount (Logarithmic Scale)', fontsize=16, labelpad=50)  # Increased labelpad  # Setting label of x-axis plt.xticks([0, 1], ['Legitimate (Class 0)', 'Fraudulent (Class 1)'], fontsize=14) plt.yticks(fontsize=12)  # Adjust y-tick font size  # Adding grid for better readability plt.grid(axis='y', linestyle='--', alpha=0.7, color='lightgrey')  # Grid line color  # Removing spines for a cleaner look sns.despine(left=True, bottom=True)  plt.show()  <p>Due to the wide range of the \u201cAmount\u201d feature, both the boxplot uses a logarithmic scale for clearer visualization, and the boxplot shows that legitimate transactions have a stable and narrow interquartile range (IQR), indicating consistent and predictable spending patterns, while fraudulent transactions have a much wider IQR ranging from around 1 to over 100, reflecting inconsistent and random behaviour in transaction value; the histogram further supports this by showing an irregular distribution for fraudulent transactions, with many small-amount transactions and several spikes at high amounts, suggesting a strategy of testing card validity with small charges before attempting larger transactions to maximize profit prior to card blockage.</p> In\u00a0[40]: Copied! <pre># Create a distribution plot for 'Amount' by 'Class'\nplt.figure(figsize=(14, 10))\nsns.histplot(data=data, x='Amount', hue='Class', palette='pastel', bins=50, kde=True, stat='density', common_norm=False, edgecolor='none')\n\n#Adding Title and Lable\nplt.title('Distribution of Transaction Amount by Class', fontsize=20, weight='bold')\nplt.xlabel('Amount', fontsize=16, labelpad=20)\nplt.ylabel('Density', fontsize=16, labelpad=20)\n\nplt.show()\n</pre> # Create a distribution plot for 'Amount' by 'Class' plt.figure(figsize=(14, 10)) sns.histplot(data=data, x='Amount', hue='Class', palette='pastel', bins=50, kde=True, stat='density', common_norm=False, edgecolor='none')  #Adding Title and Lable plt.title('Distribution of Transaction Amount by Class', fontsize=20, weight='bold') plt.xlabel('Amount', fontsize=16, labelpad=20) plt.ylabel('Density', fontsize=16, labelpad=20)  plt.show() In\u00a0[41]: Copied! <pre>plt.figure(figsize=(14, 10))\n\n#Log Transformation\ndata['LogAmount'] = np.log1p(data['Amount'])  # log(Amount + 1) to handle zeros\nsns.histplot(data=data, x='LogAmount', hue='Class', palette='pastel', bins=50, kde=True, stat='density', common_norm=False, edgecolor='none')\n\n#Adding Title and Lable\nplt.title('Log-Transformed Amount by Class', fontsize=20, weight='bold')\nplt.xlabel('Log-Amount', fontsize=16, labelpad=20)\nplt.ylabel('Density', fontsize=16, labelpad=20)\n\nplt.show()\n</pre> plt.figure(figsize=(14, 10))  #Log Transformation data['LogAmount'] = np.log1p(data['Amount'])  # log(Amount + 1) to handle zeros sns.histplot(data=data, x='LogAmount', hue='Class', palette='pastel', bins=50, kde=True, stat='density', common_norm=False, edgecolor='none')  #Adding Title and Lable plt.title('Log-Transformed Amount by Class', fontsize=20, weight='bold') plt.xlabel('Log-Amount', fontsize=16, labelpad=20) plt.ylabel('Density', fontsize=16, labelpad=20)  plt.show() <p>The histogram further supports this by showing an irregular distribution for fraudulent transactions, with many small-amount transactions and several spikes at high amounts, suggesting a strategy of testing card validity with small charges before attempting larger transactions to maximize profit prior to card blockage.</p> In\u00a0[42]: Copied! <pre>#Comparing Transactions Time\n\ndata.groupby('Class')['Time'].describe()\n</pre> #Comparing Transactions Time  data.groupby('Class')['Time'].describe() Out[42]: count mean std min 25% 50% 75% max Class 0 284315.0 94838.202258 47484.015786 0.0 54230.0 84711.0 139333.0 172792.0 1 492.0 80746.806911 47835.365138 406.0 41241.5 75568.5 128483.0 170348.0 <p>An analysis of the \u201cTime\u201d feature shows that the mean time for fraudulent transactions is lower than that of legitimate ones, indicating that fraudulent activity tends to occur earlier in the two-day observation period, and this pattern is reinforced by the median values, with half of all fraudulent transactions occurring before second 75,568.50, while half of the legitimate transactions occur later, around second 84,711.</p> In\u00a0[43]: Copied! <pre>plt.figure(figsize=(14, 10))\n\n#Histogram\nsns.histplot(data=data, x='Time', hue='Class', bins=50, kde=True, stat='density', common_norm=False, palette='pastel', edgecolor='none')\n\n#Adding Title and Lable\nplt.title('Distribution of Transaction Time by Class', fontsize=20, weight='bold')\nplt.xlabel('Time (Sec)', fontsize=16, labelpad=20)\nplt.ylabel('Density', fontsize=16, labelpad=20)\n\nplt.show()\n</pre> plt.figure(figsize=(14, 10))  #Histogram sns.histplot(data=data, x='Time', hue='Class', bins=50, kde=True, stat='density', common_norm=False, palette='pastel', edgecolor='none')  #Adding Title and Lable plt.title('Distribution of Transaction Time by Class', fontsize=20, weight='bold') plt.xlabel('Time (Sec)', fontsize=16, labelpad=20) plt.ylabel('Density', fontsize=16, labelpad=20)  plt.show() <p>Legitimate transactions appear to follow a stable pattern with high activity during daylight hours, whereas fraudulent transactions show a more random and inversely distributed pattern, and to properly analyse this daily cycle, the \u201cTime\u201d feature must be converted to represent the hour of the day to capture the cyclical nature of human behaviour.</p> In\u00a0[44]: Copied! <pre>#Daily Transaction Comparison\n\n# Calculate seconds in 24 hours (86400 seconds = 24 hours)\nseconds_in_day = data['Time'] % 86400\ndata['Hour_of_Day'] = (seconds_in_day // 3600).astype(int)\n\n#Data Visualization\n#Divide graph for 0 and 1\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12), sharex=True)\n#Plot for legitimate transactions (0)\nsns.countplot(x='Hour_of_Day', data=data[data['Class'] == 0], ax=ax1, color='#a1c9f4')\nax1.set_title('The Legitimate Transaction Distribution in a day', fontsize=14)\nax1.set_ylabel('Count', fontsize=14, labelpad=20)\nax1.set_xlabel('')\n#Plot for Fraudulent transactions (1)\nsns.countplot(x='Hour_of_Day', data=data[data['Class'] == 1], ax=ax2, color='#FFCC99', legend=0)\nax2.set_title('The Fraudulent Transaction Distribution in a day', fontsize=14)\nax2.set_xlabel('Hours a day (00.00 - 23.00)', fontsize=14, labelpad=20)\nax2.set_ylabel('Count', fontsize=14, labelpad=20)\n#Adding Title and lable\nplt.suptitle('The Comparison of Daily Transaction', fontsize=18, y=0.92, weight='bold')\nplt.tight_layout(rect=[0, 0.03, 1, 0.92])\n\nplt.show()\n</pre> #Daily Transaction Comparison  # Calculate seconds in 24 hours (86400 seconds = 24 hours) seconds_in_day = data['Time'] % 86400 data['Hour_of_Day'] = (seconds_in_day // 3600).astype(int)  #Data Visualization #Divide graph for 0 and 1 fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12), sharex=True) #Plot for legitimate transactions (0) sns.countplot(x='Hour_of_Day', data=data[data['Class'] == 0], ax=ax1, color='#a1c9f4') ax1.set_title('The Legitimate Transaction Distribution in a day', fontsize=14) ax1.set_ylabel('Count', fontsize=14, labelpad=20) ax1.set_xlabel('') #Plot for Fraudulent transactions (1) sns.countplot(x='Hour_of_Day', data=data[data['Class'] == 1], ax=ax2, color='#FFCC99', legend=0) ax2.set_title('The Fraudulent Transaction Distribution in a day', fontsize=14) ax2.set_xlabel('Hours a day (00.00 - 23.00)', fontsize=14, labelpad=20) ax2.set_ylabel('Count', fontsize=14, labelpad=20) #Adding Title and lable plt.suptitle('The Comparison of Daily Transaction', fontsize=18, y=0.92, weight='bold') plt.tight_layout(rect=[0, 0.03, 1, 0.92])  plt.show() <p>The data shows a clear peak in fraudulent transactions around 02.00 AM, when human activity is minimal. However, relying solely on this pattern would be misleading. Fraudulent transactions also occur during peak hours, as seen at 11.00 AM and in the afternoon. This suggests that analysis by hour of the day is unreliable feature for detecting fraud, as transactions happen during both peak and off-peak hours.</p> In\u00a0[45]: Copied! <pre>style.use('ggplot')\nsns.set_style('whitegrid')\nplt.subplots(figsize = (30,30))\n## Plotting heatmap. Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(data.corr(), dtype=bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(data.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0,);\nplt.title(\"Heatmap of all the Features of Train data set\", fontsize = 25);\n</pre> style.use('ggplot') sns.set_style('whitegrid') plt.subplots(figsize = (30,30)) ## Plotting heatmap. Generate a mask for the upper triangle (taken from seaborn example gallery) mask = np.zeros_like(data.corr(), dtype=bool) mask[np.triu_indices_from(mask)] = True sns.heatmap(data.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0,); plt.title(\"Heatmap of all the Features of Train data set\", fontsize = 25);  <p>As can see, some of our predictors do seem to be correlated with the Class variable. Nonetheless, there seem to be relatively little significant correlations for such a big number of variables. This can probably be attributed to two factors:</p> <ul> <li>The data was prepared using a PCA, therefore our predictors are principal components.</li> <li>The huge class imbalance might distort the importance of certain correlations with regards to our class variable.</li> </ul> <p>Because the correlation between variables and 'Class' are so small, the project choosed significant variables are the ones that have correlations with \u2018Class\u2019 \u2265 0.1.</p> In\u00a0[46]: Copied! <pre>corr = data.corr()\nplt.figure(figsize=(30,30))\nsns.heatmap((corr[(corr&gt;=0.1) |(corr &lt;=-0.1)]), mask=np.triu(corr),annot=True,center = 0,cmap=\"icefire\")\nplt.suptitle('Heatmap correlation')\nplt.show()\n</pre> corr = data.corr() plt.figure(figsize=(30,30)) sns.heatmap((corr[(corr&gt;=0.1) |(corr &lt;=-0.1)]), mask=np.triu(corr),annot=True,center = 0,cmap=\"icefire\") plt.suptitle('Heatmap correlation') plt.show() <p>We can see that V17 and V14 are the two variables that most related to the Class with the absolute correlations \u2265 0.3. Other important features are V1, V3, V4, V7, V10, V11, V12, V14, V16. V17, V18.</p> <p>The correlation analysis shows that no features are strongly correlated with fraud (|r| \u2265 0.5), with only 11 out of 30 features reaching an absolute correlation of at least 0.1, and both the \u201cAmount\u201d and \u201cTime\u201d features display very weak correlations to fraud (0.0056 and \u20130.0123), making them unsuitable as standalone fraud indicators; the \u201cV\u201d features exhibit moderate correlations as summarized in Table 4, suggesting that fraud is influenced not by simple linear relationships but by complex multivariate patterns, and because the features are not normally distributed and fraudulent values often appear in different ranges or in the tails of the distributions\u2014frequently falling outside the central quartile range in the boxplots\u2014simple linear or rule-based models are unlikely to perform well, meaning that advanced, non-linear machine learning algorithms are necessary for effective fraud detection.</p> In\u00a0[47]: Copied! <pre>nrows, ncols = len(data.columns[1:29]), 2\nfig, ax = plt.subplots(nrows, ncols, figsize = (15, 40))\n\nfor idx, col in enumerate(data.columns[1:29]):\n\n    plt.subplot(nrows, ncols, ncols*idx+1)\n    sns.histplot(data = data, x = col, bins = 30, kde = True)\n\n    plt.subplot(nrows, ncols, ncols*idx+2)\n    sns.boxplot(data = data, x = col, orient = True)\n\nplt.suptitle('Distributions of other variables')\nfig.tight_layout()\nplt.show()\n</pre> nrows, ncols = len(data.columns[1:29]), 2 fig, ax = plt.subplots(nrows, ncols, figsize = (15, 40))  for idx, col in enumerate(data.columns[1:29]):      plt.subplot(nrows, ncols, ncols*idx+1)     sns.histplot(data = data, x = col, bins = 30, kde = True)      plt.subplot(nrows, ncols, ncols*idx+2)     sns.boxplot(data = data, x = col, orient = True)  plt.suptitle('Distributions of other variables') fig.tight_layout() plt.show() In\u00a0[48]: Copied! <pre># Target'Class' column: 0 = non-fraud, 1 = fraud\nnrows, ncols = len(data.columns[1:29]), 2\nfig, ax = plt.subplots(nrows, ncols, figsize=(15, 40))\n\nfor idx, col in enumerate(data.columns[1:29]):\n    # Histogram with separate lines for Fraud and Non-Fraud\n    plt.subplot(nrows, ncols, ncols*idx + 1)\n    sns.histplot(data[data['Class'] == 0][col], bins=30, kde=True, color='skyblue', label='Non-Fraud', alpha=0.6)\n    sns.histplot(data[data['Class'] == 1][col], bins=30, kde=True, color='tomato', label='Fraud', alpha=0.6)\n    plt.legend()\n    plt.title(f'Distribution of {col}')\n\n    # Boxplot (optional: can also split by class)\n    plt.subplot(nrows, ncols, ncols*idx + 2)\n    sns.boxplot(data=data, x='Class', y=col, palette=['skyblue', 'tomato'])\n    plt.title(f'Boxplot of {col} by Class')\n    plt.xticks([0, 1], ['Non-Fraud', 'Fraud'])\n\nplt.suptitle('Distributions and Boxplots of Features by Class', fontsize=16, fontweight='bold')\nfig.tight_layout()\nplt.show()\n</pre> # Target'Class' column: 0 = non-fraud, 1 = fraud nrows, ncols = len(data.columns[1:29]), 2 fig, ax = plt.subplots(nrows, ncols, figsize=(15, 40))  for idx, col in enumerate(data.columns[1:29]):     # Histogram with separate lines for Fraud and Non-Fraud     plt.subplot(nrows, ncols, ncols*idx + 1)     sns.histplot(data[data['Class'] == 0][col], bins=30, kde=True, color='skyblue', label='Non-Fraud', alpha=0.6)     sns.histplot(data[data['Class'] == 1][col], bins=30, kde=True, color='tomato', label='Fraud', alpha=0.6)     plt.legend()     plt.title(f'Distribution of {col}')      # Boxplot (optional: can also split by class)     plt.subplot(nrows, ncols, ncols*idx + 2)     sns.boxplot(data=data, x='Class', y=col, palette=['skyblue', 'tomato'])     plt.title(f'Boxplot of {col} by Class')     plt.xticks([0, 1], ['Non-Fraud', 'Fraud'])  plt.suptitle('Distributions and Boxplots of Features by Class', fontsize=16, fontweight='bold') fig.tight_layout() plt.show() <ul> <li>Most feature histograms appear sharp, or irregular rather bell shaped, this indicates that applying a Standard Scaler may not be appropriate, as the features are not normally distributed.</li> <li>Many features show a high concentration of values near 0, suggesting strong dimensionality reduction effects, which likely due to a PCA transformation, as mentioned in the data introduction</li> <li>Value associated with fraudulent transactions are sparse because the dataset is highly imbalanced. However, these values tend to appear in different ranges or in the tails of the feature distributions. Therefore, Robust Scaler may not be suitable for this data frame, as it relies on the median and IQR, effectively ignoring the tails where an anomaly variable exists</li> <li>The boxplots confirm that, for higher correlated features that found in the EDA part, fraud cases frequently appear outside the central quartile range.</li> </ul> <p>We first establish a multivariate logistic regression baseline using all available features (Time, Amount, and V1\u2013V28). This simple linear model allows us to quantify how well the PCA-transformed variables separate fraudulent from legitimate transactions and provides a reference point for the more advanced non-linear models introduced later. The ROC\u2013AUC and Precision\u2013Recall curves below summarize the global ranking performance of this baseline classifier under severe class imbalance.</p> In\u00a0[54]: Copied! <pre>from sklearn.metrics import average_precision_score\n</pre> from sklearn.metrics import average_precision_score In\u00a0[55]: Copied! <pre># Use the dataframe from EDA: `data`\nfeature_cols = [c for c in data.columns if c != \"Class\"]\nX = data[feature_cols]\ny = data[\"Class\"]\n\nprint(f\"Using {len(feature_cols)} features: {feature_cols[:5]} \u2026\")\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.20,\n    random_state=42,\n    stratify=y\n)\n\nprint(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)\nprint(\"Fraud rate (train):\", y_train.mean(), \" Fraud rate (test):\", y_test.mean())\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled  = scaler.transform(X_test)\n\n# Fit logistic regression\nlogreg_all = LogisticRegression(\n    penalty=\"l2\",\n    solver=\"lbfgs\",\n    max_iter=1000,\n    class_weight=\"balanced\",\n    n_jobs=-1\n)\nlogreg_all.fit(X_train_scaled, y_train)\n\n# Predict &amp; evaluate\ny_proba_test = logreg_all.predict_proba(X_test_scaled)[:, 1]\ny_pred_test  = (y_proba_test &gt;= 0.5).astype(int)\n\ncm     = confusion_matrix(y_test, y_pred_test)\ncr     = classification_report(y_test, y_pred_test, digits=4)\nroc_auc = roc_auc_score(y_test, y_proba_test)\nap     = average_precision_score(y_test, y_proba_test)\n\nprint(\"=== Logistic Regression \u2013 All Features ===\")\nprint(\"Confusion Matrix:\\n\", cm)\nprint(\"\\nClassification Report:\\n\", cr)\nprint(f\"ROC-AUC: {roc_auc:.4f}\")\nprint(f\"Average Precision (AP): {ap:.4f}\")\n\n# Plot ROC curve\nfpr, tpr, _ = roc_curve(y_test, y_proba_test)\nplt.figure(figsize=(6,5))\nplt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.4f})\")\nplt.plot([0,1],[0,1],\"--\", color=\"grey\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve \u2013 Logistic Regression (All Features)\")\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()\n\n# Plot Precision\u2013Recall curve\nprecision, recall, _ = precision_recall_curve(y_test, y_proba_test)\nplt.figure(figsize=(6,5))\nplt.step(recall, precision, where='post', label=f\"AP={ap:.4f}\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision\u2013Recall Curve \u2013 Logistic Regression (All Features)\")\nplt.legend(loc=\"upper right\")\nplt.grid(True)\nplt.show()\n</pre> # Use the dataframe from EDA: `data` feature_cols = [c for c in data.columns if c != \"Class\"] X = data[feature_cols] y = data[\"Class\"]  print(f\"Using {len(feature_cols)} features: {feature_cols[:5]} \u2026\")  # Train-test split X_train, X_test, y_train, y_test = train_test_split(     X, y,     test_size=0.20,     random_state=42,     stratify=y )  print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape) print(\"Fraud rate (train):\", y_train.mean(), \" Fraud rate (test):\", y_test.mean())  # Scale features scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled  = scaler.transform(X_test)  # Fit logistic regression logreg_all = LogisticRegression(     penalty=\"l2\",     solver=\"lbfgs\",     max_iter=1000,     class_weight=\"balanced\",     n_jobs=-1 ) logreg_all.fit(X_train_scaled, y_train)  # Predict &amp; evaluate y_proba_test = logreg_all.predict_proba(X_test_scaled)[:, 1] y_pred_test  = (y_proba_test &gt;= 0.5).astype(int)  cm     = confusion_matrix(y_test, y_pred_test) cr     = classification_report(y_test, y_pred_test, digits=4) roc_auc = roc_auc_score(y_test, y_proba_test) ap     = average_precision_score(y_test, y_proba_test)  print(\"=== Logistic Regression \u2013 All Features ===\") print(\"Confusion Matrix:\\n\", cm) print(\"\\nClassification Report:\\n\", cr) print(f\"ROC-AUC: {roc_auc:.4f}\") print(f\"Average Precision (AP): {ap:.4f}\")  # Plot ROC curve fpr, tpr, _ = roc_curve(y_test, y_proba_test) plt.figure(figsize=(6,5)) plt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.4f})\") plt.plot([0,1],[0,1],\"--\", color=\"grey\") plt.xlabel(\"False Positive Rate\") plt.ylabel(\"True Positive Rate\") plt.title(\"ROC Curve \u2013 Logistic Regression (All Features)\") plt.legend(loc=\"lower right\") plt.grid(True) plt.show()  # Plot Precision\u2013Recall curve precision, recall, _ = precision_recall_curve(y_test, y_proba_test) plt.figure(figsize=(6,5)) plt.step(recall, precision, where='post', label=f\"AP={ap:.4f}\") plt.xlabel(\"Recall\") plt.ylabel(\"Precision\") plt.title(\"Precision\u2013Recall Curve \u2013 Logistic Regression (All Features)\") plt.legend(loc=\"upper right\") plt.grid(True) plt.show() <pre>Using 32 features: ['Time', 'V1', 'V2', 'V3', 'V4'] \u2026\nTrain size: (227845, 32)  Test size: (56962, 32)\nFraud rate (train): 0.001729245759178389  Fraud rate (test): 0.0017204452090867595\n=== Logistic Regression \u2013 All Features ===\nConfusion Matrix:\n [[55373  1491]\n [    9    89]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.9998    0.9738    0.9866     56864\n           1     0.0563    0.9082    0.1061        98\n\n    accuracy                         0.9737     56962\n   macro avg     0.5281    0.9410    0.5464     56962\nweighted avg     0.9982    0.9737    0.9851     56962\n\nROC-AUC: 0.9733\nAverage Precision (AP): 0.7225\n</pre> <p>The multivariate logistic regression baseline performs surprisingly well given the linear assumptions. The model achieves a ROC-AUC of 0.9733 and an Average Precision of 0.7225, indicating strong ranking ability even under extreme class imbalance.</p> <p>However, when using the default classification threshold of 0.5, the model produces high recall (0.908) but very low precision (0.056) for the fraud class. This behaviour is typical for imbalanced fraud problems: the model successfully prioritizes most fraudulent transactions but generates many false alarms.</p> <p>The Precision\u2013Recall curve confirms this pattern: the model demonstrates excellent precision at low recall, meaning that the top-scored predictions are highly reliable. Precision declines as recall increases, reflecting the natural trade-off between catching more fraud and minimizing false positives.</p> <p>This baseline result highlights that:</p> <ul> <li><p>Logistic regression captures meaningful fraud patterns (high AUC, high AP)</p> </li> <li><p>Default thresholds are unsuitable</p> </li> <li><p>Threshold optimization or non-linear models (RF, XGB, Hybrid) are needed to improve precision without sacrificing recall</p> </li> </ul>"},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#exploratory-data-analysis-eda","title":"Exploratory Data Analysis (EDA)\u00b6","text":"<p>This dataset is the result of a research collaboration between Worldline, a major company in the payment industry, and The Machine Learning Group from Universit\u00e9 Libre de Bruxelles (ULB). The dataset used in this analysis is a Credit Card Fraud Detection from the transactions made by European cardholders over two days in September 2013. The total number of transactions is 284,807, consisting of 31 columns and including 30 input features and one binary target variable.</p>"},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#1-library-importing","title":"1. Library importing\u00b6","text":""},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#2-data-exploration-analysis","title":"2. Data exploration analysis\u00b6","text":""},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#21-class","title":"2.1. Class\u00b6","text":""},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#22-amount-by-class","title":"2.2. Amount by Class\u00b6","text":""},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#23-time-by-class","title":"2.3. Time by Class\u00b6","text":""},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#23-pca-variables","title":"2.3. PCA Variables\u00b6","text":""},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#25-multivariate-regression-model-base","title":"2.5. Multivariate Regression Model (Base)\u00b6","text":""},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#26-eda-conclusion","title":"2.6. EDA Conclusion\u00b6","text":"<ol> <li><p>The finding on \u2018Amount\u2019 feature indicates that most fraudulent transactions involve small amounts, but a few extremely large transactions. This pattern likely indicates a fraudulent strategy to test card validation by making small-amount transactions, followed by a few high-amount transaction in terms of maximazing profit before the card is blocked.</p> </li> <li><p>The finding on \u2018Time\u2019 feature shows which fraudulent transactions often occur when human activity decreases, such as in the late night (02.00 AM). However, fraudulent transactions also occur during peak hours, as seen at 11.00 AM and in the afternoon. This suggests that analysis by hour of the day is unreliable feature for detecting fraud, as transactions happen during both peak and off-peak hours.</p> </li> <li><p>The correlation analysis reveals that no features stand out as highly correlated (&gt; 0.5 or \u2264 0.5) with fraud. This indicates that fraud is not a simple linear function but instead determined by complex, multivariate patterns. This finding suggests that simple linear models or static rule-based systems will likely be ineffective. Hence, the use of advanced, non-linear machine learning algorithms is essential.</p> </li> </ol>"},{"location":"notebooks/EDA_Risk_Analytics_PLA_Credit_Card_Fraud/#27-summary","title":"2.7. Summary\u00b6","text":"<p>The current project aimed to have a further understanding with real-life fraud transaction data and construct, evaluate a comprehensive fraud detection framework. The analysis was conducted using the Credit Card Fraud Detection dataset, which has been widely used for testing and developing different approaches to financial fraud transactions. In the scope of these projects, our exploration data analysis (EDA) and predictive model building effort have generated new findings to this model, which lead to practical implementation and future research.</p> <p>The EDA identified important behavioural and statistical differences between legitimate and fraudulent transactions. Analysing the number of transactions, the result showed that fraudulent transactions generally involved smaller amounts, but occasionally high-value outliers also appeared, reflecting that fraudsters\u2019 strategy is to test card validity with small purchases before conducting large unauthorized ones. \u2018Time\u2019 feature further revealed that fraudulent activity is more likely to happen during off-peak hours, particularly around 2:00 am, when legitimate user activity is minimal. Correlation analysis indicated that only 11 of 30 features (V1 - V28, Amount, and Time) had an absolute correlation with fraud greater than 0.1, and none above 0.5, confirming that fraud cannot be captured through linear relationships and requires non-linear, multivariate learning techniques. The distributions of features show that most of the variables, especially higher correlated features, are not normally distributed, and the fraud transactions mostly appear in different ranges or in the tails of the feature distribution.</p>"},{"location":"notebooks/ExtraModels_Risk_Analytics_PLA_Credit_Card_Fraud/","title":"ExtraModels Risk Analytics PLA Credit Card Fraud","text":"<p>Overall: The performance of the AdaBoost model surpasses that of the unsupervised approaches; however, it remains inferior to the XGBoost and Random Forest models. Specifically, AdaBoost successfully identified approximately 90% of fraudulent transactions but exhibited a relatively low precision (0.0877), meaning that a high incidence of false alarms and according to the confusion matrix, mostly fell into false positives. Nevertheless, with an overall accuracy of 0.9836, the AdaBoost model can still be regarded as a reasonably effective classification method within this context.</p> In\u00a0[\u00a0]: Copied! <pre>from sklearn.ensemble import AdaBoostClassifier\n\n# Train AdaBoost model\nada_model = AdaBoostClassifier(\n    random_state=0,\n    algorithm='SAMME',\n    learning_rate=0.5,\n    n_estimators=100\n)\n\n# Fit model and make predictions\nmodel, y_pred = Models(ada_model, X_train, X_test, y_train, y_test, df, title=\"AdaBoost / SMOTE\")\n</pre> from sklearn.ensemble import AdaBoostClassifier  # Train AdaBoost model ada_model = AdaBoostClassifier(     random_state=0,     algorithm='SAMME',     learning_rate=0.5,     n_estimators=100 )  # Fit model and make predictions model, y_pred = Models(ada_model, X_train, X_test, y_train, y_test, df, title=\"AdaBoost / SMOTE\") In\u00a0[\u00a0]: Copied! <pre># Feature importances\nimp_df = FeatureImportances(ada_model, X_train, y_train, df)\nprint(imp_df)\n</pre> # Feature importances imp_df = FeatureImportances(ada_model, X_train, y_train, df) print(imp_df) <pre>   Feature  Importance  Cumulative Importance\n0       V4    0.256805               0.409354\n1      V14    0.179490               0.857148\n2       V1    0.089257               0.102619\n3      V10    0.084256               0.596361\n4      V12    0.068312               0.677658\n5       V3    0.049930               0.152550\n6      V17    0.047868               0.950494\n7      V16    0.045478               0.902626\n8       V9    0.044831               0.512105\n9       V8    0.028097               0.467274\n10      V6    0.017116               0.426470\n11     V21    0.015014               0.989553\n12     V19    0.014434               0.974539\n13    Time    0.013362               0.013362\n14     V11    0.012985               0.609346\n15      V7    0.012707               0.439176\n16     V22    0.010447               1.000000\n17     V18    0.009611               0.960105\n18     V26    0.000000               1.000000\n19     V24    0.000000               1.000000\n20     V27    0.000000               1.000000\n21     V25    0.000000               1.000000\n22     V28    0.000000               1.000000\n23     V15    0.000000               0.857148\n24     V23    0.000000               1.000000\n25     V20    0.000000               0.974539\n26     V13    0.000000               0.677658\n27      V5    0.000000               0.409354\n28      V2    0.000000               0.102619\n29  Amount    0.000000               1.000000\n</pre> <p>The top eight features account for 82.14% of the total feature importance in the AdaBoost model, indicating that these variables play a dominant role in shaping its predictive capability. Among them, V4 is identified as the most influential feature, contributing 23.68%, followed by V14 with 17.95%. These eight features show a strong correlation with the target variable (Class) and are also recognized as key predictors in the Random Forest model, suggesting consistency across different ensemble learning approaches.</p> <p>In contrast, 12 features, including \u201cAmount\u201d, V2, V5, V13, V15, V20, and V23\u2013V28, exhibit no measurable contribution to the model\u2019s performance, implying that they provide minimal or redundant information for fraud detection within this dataset.</p> In\u00a0[\u00a0]: Copied! <pre># Full dataset\nX_all, y_all = Definedata(df)\n\n# Classification report\nreport = classification_report(y_all, y_pred, digits=4)\nprint(\"Classification Report (Full Dataset)\")\nprint(report)\n\n# Get probabilities for the positive class (Class=1)\ny_proba_ada = ada_model.predict_proba(X_all)[:,1]\n\n# ROC-AUC\nroc_auc_ada = roc_auc_score(y_all, y_proba_ada)\nprint(f\"ROC AUC Score (Full Dataset): {roc_auc_ada:.5f}\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_all, y_pred)\ncm_df = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],\n                     columns=[f\"Pred_{i}\" for i in range(cm.shape[1])])\nprint(\"Confusion Matrix (Full Dataset):\")\nprint(cm_df)\n</pre> # Full dataset X_all, y_all = Definedata(df)  # Classification report report = classification_report(y_all, y_pred, digits=4) print(\"Classification Report (Full Dataset)\") print(report)  # Get probabilities for the positive class (Class=1) y_proba_ada = ada_model.predict_proba(X_all)[:,1]  # ROC-AUC roc_auc_ada = roc_auc_score(y_all, y_proba_ada) print(f\"ROC AUC Score (Full Dataset): {roc_auc_ada:.5f}\")  # Confusion Matrix cm = confusion_matrix(y_all, y_pred) cm_df = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],                      columns=[f\"Pred_{i}\" for i in range(cm.shape[1])]) print(\"Confusion Matrix (Full Dataset):\") print(cm_df) <pre>Classification Report (Full Dataset)\n              precision    recall  f1-score   support\n\n           0     0.9998    0.9838    0.9917    284315\n           1     0.0877    0.9004    0.1598       492\n\n    accuracy                         0.9836    284807\n   macro avg     0.5438    0.9421    0.5758    284807\nweighted avg     0.9982    0.9836    0.9903    284807\n\nROC AUC Score (Full Dataset): 0.98654\nConfusion Matrix (Full Dataset):\n          Pred_0  Pred_1\nActual_0  279706    4609\nActual_1      49     443\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculate ROC curve points\nfpr, tpr, thresholds = roc_curve(y_all, y_proba_ada)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_ada:.5f})')\nplt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve - AdaBoost', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Calculate ROC curve points fpr, tpr, thresholds = roc_curve(y_all, y_proba_ada)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_ada:.5f})') plt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve - AdaBoost', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show() In\u00a0[\u00a0]: Copied! <pre># Calculate Gini coefficient\ngini_ada = 2 * roc_auc_ada - 1\nprint(f\"Gini Coefficient of AdaBoost: {gini_ada:.4f}\")\n</pre> # Calculate Gini coefficient gini_ada = 2 * roc_auc_ada - 1 print(f\"Gini Coefficient of AdaBoost: {gini_ada:.4f}\") <pre>Gini Coefficient of AdaBoost: 0.9731\n</pre> <p>The ROC curve illustrates that the AdaBoost model performs effectively in detecting fraudulent transactions, demonstrating a classification ability that is substantially superior to random guessing. The model achieves a GINI of 0.9731, a value approaching 1, indicating a relatively strong level of discriminatory power between fraudulent and legitimate cases.</p> <p>Overall: Though it can detect all fraudulent transactions and has no false negatives, Light GBM has the lowest level of accuracy between the assessed machine learning algorithms (0.7627). The model has extremely low precision (0.0072) and F1-score (0.0144), and the scores are explained further by the confusion matrix, where 67,578 normal transactions are misclassified as fraud.  Although this yields a very high ROC AUC score of 0.9946, indicating excellent overall ranking ability, the model\u2019s real-world applicability is limited because it would generate an excessive number of false alarms in operational settings.</p> In\u00a0[\u00a0]: Copied! <pre># LightGBM parameters\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'num_leaves': 7,              # should be smaller than 2^(max_depth)\n    'max_depth': 4,               # -1 means no limit\n    'min_child_samples': 100,     # minimum data in one leaf\n    'max_bin': 100,               # number of bins for feature values\n    'subsample': 0.9,             # subsample ratio for training data\n    'subsample_freq': 1,          # frequency of subsampling\n    'colsample_bytree': 0.7,      # ratio of columns for each tree\n    'min_child_weight': 0,        # minimum sum of instance weight in a leaf\n    'min_split_gain': 0,          # minimum loss reduction required to make a split\n    'nthread': 8,\n    'verbose': 0,\n    'scale_pos_weight': 150       # for highly imbalanced data\n}\n\n# Train LightGBM model\nlgbm_model = LGBMClassifier(random_state=0, **params)\n\n# Fit model and make predictions (using your custom Models() function)\nmodel, y_pred = Models(lgbm_model, X_train, X_test, y_train, y_test, df, title=\"LightGBM / SMOTE\")\n</pre> # LightGBM parameters params = {     'boosting_type': 'gbdt',     'objective': 'binary',     'metric': 'auc',     'learning_rate': 0.05,     'num_leaves': 7,              # should be smaller than 2^(max_depth)     'max_depth': 4,               # -1 means no limit     'min_child_samples': 100,     # minimum data in one leaf     'max_bin': 100,               # number of bins for feature values     'subsample': 0.9,             # subsample ratio for training data     'subsample_freq': 1,          # frequency of subsampling     'colsample_bytree': 0.7,      # ratio of columns for each tree     'min_child_weight': 0,        # minimum sum of instance weight in a leaf     'min_split_gain': 0,          # minimum loss reduction required to make a split     'nthread': 8,     'verbose': 0,     'scale_pos_weight': 150       # for highly imbalanced data }  # Train LightGBM model lgbm_model = LGBMClassifier(random_state=0, **params)  # Fit model and make predictions (using your custom Models() function) model, y_pred = Models(lgbm_model, X_train, X_test, y_train, y_test, df, title=\"LightGBM / SMOTE\")  In\u00a0[\u00a0]: Copied! <pre># Feature importances\nimp_df = FeatureImportances(lgbm_model, X_train, y_train, df)\nprint(imp_df)\n</pre> # Feature importances imp_df = FeatureImportances(lgbm_model, X_train, y_train, df) print(imp_df) <pre>   Feature  Importance  Cumulative Importance\n0       V4          95                    245\n1      V14          82                    494\n2       V1          52                     91\n3       V8          48                    308\n4      V12          47                    404\n5       V3          43                    150\n6     Time          39                     39\n7      V10          30                    341\n8      V11          16                    357\n9       V2          16                    107\n10     V18          15                    527\n11     V19          11                    538\n12     V25          10                    583\n13     V16          10                    506\n14      V5           9                    254\n15     V13           8                    412\n16     V20           8                    546\n17     V22           8                    561\n18     V24           7                    573\n19     V26           7                    590\n20     V21           7                    553\n21     V17           6                    512\n22     V23           5                    566\n23  Amount           5                    600\n24      V6           5                    259\n25      V9           3                    311\n26     V28           3                    595\n27     V27           2                    592\n28     V15           2                    496\n29      V7           1                    260\n</pre> In\u00a0[\u00a0]: Copied! <pre># Full dataset\nX_all, y_all = Definedata(df)\n\n# classification report\nreport = classification_report(y_all, y_pred, digits=4)\nprint(\"Classification Report (Full Dataset)\")\nprint(report)\n\n# Get probabilities for the positive class (Class=1)\ny_proba_lgbm = lgbm_model.predict_proba(X_all)[:,1]\n\n# ROC-AUC\nroc_auc_lgbm = roc_auc_score(y_all, y_proba_lgbm)\nprint(f\"ROC AUC Score (Full Dataset): {roc_auc:.5f}\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_all, y_pred)\ncm_df = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],\n                     columns=[f\"Pred_{i}\" for i in range(cm.shape[1])])\nprint(\"Confusion Matrix (Full Dataset):\")\nprint(cm_df)\n</pre> # Full dataset X_all, y_all = Definedata(df)  # classification report report = classification_report(y_all, y_pred, digits=4) print(\"Classification Report (Full Dataset)\") print(report)  # Get probabilities for the positive class (Class=1) y_proba_lgbm = lgbm_model.predict_proba(X_all)[:,1]  # ROC-AUC roc_auc_lgbm = roc_auc_score(y_all, y_proba_lgbm) print(f\"ROC AUC Score (Full Dataset): {roc_auc:.5f}\")  # Confusion Matrix cm = confusion_matrix(y_all, y_pred) cm_df = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],                      columns=[f\"Pred_{i}\" for i in range(cm.shape[1])]) print(\"Confusion Matrix (Full Dataset):\") print(cm_df) <pre>Classification Report (Full Dataset)\n              precision    recall  f1-score   support\n\n           0     1.0000    0.7623    0.8651    284315\n           1     0.0072    1.0000    0.0144       492\n\n    accuracy                         0.7627    284807\n   macro avg     0.5036    0.8812    0.4397    284807\nweighted avg     0.9983    0.7627    0.8637    284807\n\nROC AUC Score (Full Dataset): 0.95497\nConfusion Matrix (Full Dataset):\n          Pred_0  Pred_1\nActual_0  216737   67578\nActual_1       0     492\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculate ROC curve points\nfpr, tpr, thresholds = roc_curve(y_all, y_proba_lgbm)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_lgbm:.5f})')\nplt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve - LightGBM', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Calculate ROC curve points fpr, tpr, thresholds = roc_curve(y_all, y_proba_lgbm)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_lgbm:.5f})') plt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve - LightGBM', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show() In\u00a0[\u00a0]: Copied! <pre># Calculate Gini coefficient\ngini_lgbm = 2 * roc_auc_lgbm - 1\nprint(f\"Gini Coefficient of CatBoost: {gini_lgbm:.4f}\")\n</pre> # Calculate Gini coefficient gini_lgbm = 2 * roc_auc_lgbm - 1 print(f\"Gini Coefficient of CatBoost: {gini_lgbm:.4f}\") <pre>Gini Coefficient of CatBoost: 0.9891\n</pre> <p>The feature importance table for Light GBM shows the split importance, or the number of times the model used each feature to split data. In total, the model split 600 times, the top 11 accounts for 487 times or 80% number the needed time splits. Besides familiar highly correlated features, the other important ones are V8, \u2018Time\u2019, and V2.</p> <p>The ROC curve illustrates that the Light GBM is still considered as effective method for fraud detection. The model achieves a GINI of 0.0.99457, approaching 1, indicating a relatively strong level of discriminatory power between fraudulent and legitimate cases.</p> <p>Summary of supervised learning methods</p> <p>The results of supervised learning algorithms are much more precise than unsupervised ones. The Random Forest so far is the best performing model with the highest F1-score (0.9685), and according to its confusion matrix, there are no false negatives and 32 false positives. XGBoots and CatBoots both have good recalls and no false negatives, but XGBoots slightly performs better than CatBoots with higher Precision (1) and F1-score (1). On the other hand, AdaBoost and LightGBM have really poor overall balance with F1-score (1) equal to 0.1598 and 0.0144, respectively. LightGBM is the worst-performing with extremely low Precision (1) (0.0072), which is even lower than the Anomaly detection models\u2019 performances, reflecting severe overprediction of the minority class. Furthermore, the results also showed that the most important features for the models are likely the ones that have better correlations with \u2018Class\u2019, but not all listed high correlation features have great contributions to the Machine Learning model. Therefore, the outcomes of detecting fraudulent transactions on highly correlated data frames are significantly worse than using the whole original one, indicating that the whole dataframe must be used as an input for machine learning methods and hybrid methods that are based on supervised algorithms.</p>"},{"location":"notebooks/ExtraModels_Risk_Analytics_PLA_Credit_Card_Fraud/#54-adaboost-classifier","title":"5.4. AdaBoost Classifier\u00b6","text":""},{"location":"notebooks/ExtraModels_Risk_Analytics_PLA_Credit_Card_Fraud/#56-light-gbm","title":"5.6. Light GBM\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/","title":"Machine Learning Models","text":"In\u00a0[27]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nstyle.use('ggplot')\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n%matplotlib inline\npd.options.mode.chained_assignment = None\nimport matplotlib.font_manager\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom typing import Dict, List\nfrom sklearn import ensemble\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport plotly.figure_factory as ff\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib.style as style style.use('ggplot') import matplotlib.gridspec as gridspec import seaborn as sns sns.set_style(\"darkgrid\") %matplotlib inline pd.options.mode.chained_assignment = None import matplotlib.font_manager from scipy.stats import norm from scipy import stats from sklearn.model_selection import train_test_split from sklearn.model_selection import GridSearchCV from sklearn.model_selection import cross_val_score from sklearn.pipeline import Pipeline, make_pipeline from sklearn.preprocessing import StandardScaler, PolynomialFeatures from sklearn.ensemble import IsolationForest from sklearn.linear_model import LinearRegression from sklearn.linear_model import LogisticRegression from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc from sklearn.tree import DecisionTreeRegressor from sklearn.ensemble import RandomForestRegressor from sklearn.cluster import DBSCAN from sklearn.neighbors import LocalOutlierFactor from sklearn.svm import OneClassSVM from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score from typing import Dict, List from sklearn import ensemble import warnings warnings.filterwarnings(\"ignore\") import plotly.figure_factory as ff from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot  In\u00a0[28]: Copied! <pre>!pip install --upgrade statsmodels\nimport statsmodels.api as sm\n</pre> !pip install --upgrade statsmodels import statsmodels.api as sm  <pre>Requirement already satisfied: statsmodels in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (0.14.5)\nRequirement already satisfied: patsy&gt;=0.5.6 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (1.0.2)\nRequirement already satisfied: pandas!=2.1.0,&gt;=1.4 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (1.5.3)\nRequirement already satisfied: packaging&gt;=21.3 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (22.0)\nRequirement already satisfied: numpy&lt;3,&gt;=1.22.3 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (1.26.4)\nRequirement already satisfied: scipy!=1.9.2,&gt;=1.8 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from statsmodels) (1.10.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2022.7)\nRequirement already satisfied: six&gt;=1.5 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from python-dateutil&gt;=2.8.1-&gt;pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (1.16.0)\n</pre> In\u00a0[29]: Copied! <pre>!pip install tensorflow\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nfrom tensorflow.keras.regularizers import l2\n</pre> !pip install tensorflow  import tensorflow as tf from tensorflow.keras.models import Model from tensorflow.keras.layers import Input, Dense, Dropout from tensorflow.keras.regularizers import l2 <pre>Requirement already satisfied: tensorflow in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: wrapt&gt;=1.11.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: ml_dtypes&lt;1.0.0,&gt;=0.5.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.5.3)\nRequirement already satisfied: absl-py&gt;=1.0.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.3.1)\nRequirement already satisfied: packaging in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (22.0)\nRequirement already satisfied: tensorboard~=2.20.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.20.0)\nRequirement already satisfied: astunparse&gt;=1.6.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: typing_extensions&gt;=3.6.6 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.15.0)\nRequirement already satisfied: opt_einsum&gt;=2.3.2 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: setuptools in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (65.6.3)\nRequirement already satisfied: flatbuffers&gt;=24.3.25 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (25.9.23)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,&gt;=0.2.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: termcolor&gt;=1.1.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.2.0)\nRequirement already satisfied: google_pasta&gt;=0.1.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy&gt;=1.26.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py&gt;=3.11.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.15.1)\nRequirement already satisfied: libclang&gt;=13.0.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: six&gt;=1.12.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.76.0)\nRequirement already satisfied: protobuf&gt;=5.28.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (6.33.1)\nRequirement already satisfied: requests&lt;3,&gt;=2.21.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.28.1)\nRequirement already satisfied: keras&gt;=3.10.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.12.0)\nRequirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from astunparse&gt;=1.6.0-&gt;tensorflow) (0.38.4)\nRequirement already satisfied: namex in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from keras&gt;=3.10.0-&gt;tensorflow) (0.1.0)\nRequirement already satisfied: optree in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from keras&gt;=3.10.0-&gt;tensorflow) (0.18.0)\nRequirement already satisfied: rich in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from keras&gt;=3.10.0-&gt;tensorflow) (14.2.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow) (1.26.14)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow) (2025.11.12)\nRequirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow) (3.4)\nRequirement already satisfied: pillow in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorboard~=2.20.0-&gt;tensorflow) (9.4.0)\nRequirement already satisfied: werkzeug&gt;=1.0.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorboard~=2.20.0-&gt;tensorflow) (3.0.3)\nRequirement already satisfied: markdown&gt;=2.6.8 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorboard~=2.20.0-&gt;tensorflow) (3.4.1)\nRequirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from tensorboard~=2.20.0-&gt;tensorflow) (0.7.2)\nRequirement already satisfied: MarkupSafe&gt;=2.1.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard~=2.20.0-&gt;tensorflow) (2.1.1)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from rich-&gt;keras&gt;=3.10.0-&gt;tensorflow) (2.19.2)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from rich-&gt;keras&gt;=3.10.0-&gt;tensorflow) (4.0.0)\nRequirement already satisfied: mdurl~=0.1 in /Users/panguyen277/anaconda3/lib/python3.10/site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras&gt;=3.10.0-&gt;tensorflow) (0.1.2)\n</pre> In\u00a0[30]: Copied! <pre>from sklearn.metrics import precision_recall_curve\n</pre> from sklearn.metrics import precision_recall_curve In\u00a0[31]: Copied! <pre>#Data load\nfile_path = \"/Users/panguyen277/Downloads/creditcard.csv\"\n\ndf = pd.read_csv(file_path)\nprint(df.head())\n</pre> #Data load file_path = \"/Users/panguyen277/Downloads/creditcard.csv\"  df = pd.read_csv(file_path) print(df.head()) <pre>   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]\n</pre> In\u00a0[\u00a0]: Copied! <pre>#Features name\nfeatures = df.columns[:-1]\n\n# Create a copy of the DataFrame to avoid changing the original\ndf_transformed = df.copy()\n\n# Function to handle log transformation for skewed data\ndef log_transform_skewed(column):\n    # For positive and zero values (log1p avoids log(0) errors)\n    transformed = np.where(column &gt;= 0, np.log1p(column), -np.log1p(-column))\n    return transformed\n\n# Compute skewness before transformation\nskewness_before = df.skew()\n\n# Apply transformation to skewed columns\nfor col in features:\n    if abs(df[col].skew()) &gt; 0.75:  # Threshold for skewness\n        df_transformed[col] = log_transform_skewed(df[col])\n\n# Compute skewness after transformation\nskewness_after = df_transformed.skew()\n\n# Compare skewness before and after\nskewness_comparison = pd.DataFrame({\n    'Skewness Before': skewness_before,\n    'Skewness After': skewness_after\n})\n\n# Print the comparison\nskewness_comparison\n</pre> #Features name features = df.columns[:-1]  # Create a copy of the DataFrame to avoid changing the original df_transformed = df.copy()  # Function to handle log transformation for skewed data def log_transform_skewed(column):     # For positive and zero values (log1p avoids log(0) errors)     transformed = np.where(column &gt;= 0, np.log1p(column), -np.log1p(-column))     return transformed  # Compute skewness before transformation skewness_before = df.skew()  # Apply transformation to skewed columns for col in features:     if abs(df[col].skew()) &gt; 0.75:  # Threshold for skewness         df_transformed[col] = log_transform_skewed(df[col])  # Compute skewness after transformation skewness_after = df_transformed.skew()  # Compare skewness before and after skewness_comparison = pd.DataFrame({     'Skewness Before': skewness_before,     'Skewness After': skewness_after })  # Print the comparison skewness_comparison  Out[\u00a0]: Skewness Before Skewness After Time -0.035568 -0.035568 V1 -3.280667 -0.364893 V2 -4.624866 -0.310128 V3 -2.240155 -0.315192 V4 0.676292 0.676292 V5 -2.425901 0.139077 V6 1.826581 0.804345 V7 2.553907 -0.112666 V8 -8.521944 -0.912642 V9 0.554680 0.554680 V10 1.187141 0.420549 V11 0.356506 0.356506 V12 -2.278401 -0.616600 V13 0.065233 0.065233 V14 -1.995176 -0.279434 V15 -0.308423 -0.308423 V16 -1.100966 -0.262415 V17 -3.844914 0.278791 V18 -0.259880 -0.259880 V19 0.109192 0.109192 V20 -2.037155 0.605080 V21 3.592991 0.590471 V22 -0.213258 -0.213258 V23 -5.875140 0.099389 V24 -0.552499 -0.552499 V25 -0.415793 -0.415793 V26 0.576693 0.576693 V27 -1.170209 -0.754107 V28 11.192091 -0.601426 Amount 16.977724 0.162703 Class 23.997579 23.997579 In\u00a0[\u00a0]: Copied! <pre># Set up the figure; 10 rows (10*3=30 subplots), adjust as needed\nfig, axes = plt.subplots(10, 3, figsize=(15, 40))  # Adjust rows to fit all features\n\n# Flatten axes array to loop through easily\naxes = axes.flatten()\n\n# Plot each feature in a separate subplot\nfor i, feature in enumerate(features):\n    sns.histplot(df_transformed[feature], ax=axes[i], kde=False, bins=30)\n    axes[i].set_title(f'{feature} after Transformation')\n    axes[i].set_xlabel(feature)\n    axes[i].set_ylabel('Frequency')\n\n# Remove any unused subplots if features &lt; 30\nfor i in range(len(features), len(axes)):\n    fig.delaxes(axes[i])\n\nplt.tight_layout()\nplt.show()\n</pre> # Set up the figure; 10 rows (10*3=30 subplots), adjust as needed fig, axes = plt.subplots(10, 3, figsize=(15, 40))  # Adjust rows to fit all features  # Flatten axes array to loop through easily axes = axes.flatten()  # Plot each feature in a separate subplot for i, feature in enumerate(features):     sns.histplot(df_transformed[feature], ax=axes[i], kde=False, bins=30)     axes[i].set_title(f'{feature} after Transformation')     axes[i].set_xlabel(feature)     axes[i].set_ylabel('Frequency')  # Remove any unused subplots if features &lt; 30 for i in range(len(features), len(axes)):     fig.delaxes(axes[i])  plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># Separate features and target\nX = df_transformed[features]\ny = df_transformed['Class']\n\nfrom sklearn.preprocessing import MinMaxScaler\n# Standardize the data\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)\n</pre> # Separate features and target X = df_transformed[features] y = df_transformed['Class']  from sklearn.preprocessing import MinMaxScaler # Standardize the data scaler = MinMaxScaler() X_scaled = scaler.fit_transform(X) In\u00a0[\u00a0]: Copied! <pre>print(X)\n</pre> print(X) <pre>            Time        V1        V2        V3        V4        V5        V6  \\\n0            0.0 -0.858580 -0.070255  1.263094  1.378155 -0.291416  0.380071   \n1            0.0  0.784749  0.235981  0.153991  0.448154  0.058286 -0.079145   \n2            1.0 -0.857964 -0.850221  1.020005  0.379780 -0.407595  1.029798   \n3            1.0 -0.676139 -0.169933  1.027114 -0.863291 -0.010256  0.809686   \n4            2.0 -0.769290  0.630067  0.935590  0.403034 -0.341597  0.091596   \n...          ...       ...       ...       ...       ...       ...       ...   \n284802  172786.0 -2.555763  2.404400 -2.382762 -2.066656 -1.850731 -1.282831   \n284803  172787.0 -0.549732 -0.053617  1.110221 -0.738589  0.624991  0.721936   \n284804  172788.0  1.071435 -0.263328 -1.446834 -0.557828  1.289375  1.394079   \n284805  172788.0 -0.215466  0.425583  0.532104  0.689799 -0.320605  0.484712   \n284806  172792.0 -0.427496 -0.173729  0.532589 -0.506271 -0.012468 -0.500543   \n\n              V7        V8        V9  ...       V20       V21       V22  \\\n0       0.214788  0.094126  0.363787  ...  0.224273 -0.018141  0.277838   \n1      -0.075852  0.081674 -0.255425  ... -0.066801 -0.203573 -0.638672   \n2       0.583031  0.221282 -1.514654  ...  0.421981  0.221541  0.771679   \n3       0.213181  0.320224 -1.387024  ... -0.188997 -0.102828  0.005274   \n4       0.465582 -0.239436  0.817739  ...  0.342555 -0.009387  0.798278   \n...          ...       ...       ...  ...       ...       ...       ...   \n284802 -1.778035  2.116898  1.914428  ...  0.906575  0.193471  0.111864   \n284803  0.024038  0.258409  0.584800  ...  0.057906  0.194090  0.924384   \n284804 -0.259920  0.535567  0.432454  ...  0.001395  0.208675  0.578229   \n284805 -0.522466  0.518285  0.392087  ...  0.119944  0.235266  0.800049   \n284806  0.946628 -0.346882  0.486180  ...  0.324218  0.231951  0.643078   \n\n             V23       V24       V25       V26       V27       V28    Amount  \n0      -0.104787  0.066928  0.128539 -0.189115  0.125362 -0.020835  5.014760  \n1       0.096480 -0.339846  0.167170  0.125895 -0.008943  0.014617  1.305626  \n2       0.646795 -0.689281 -0.327642 -0.139097 -0.053875 -0.058035  5.939276  \n3      -0.174223 -1.175575  0.647376 -0.221929  0.060834  0.059643  4.824306  \n4      -0.128796  0.141267 -0.206010  0.502292  0.198377  0.194870  4.262539  \n...          ...       ...       ...       ...       ...       ...       ...  \n284802  0.700361 -0.509348  1.436807  0.250034  0.664568  0.600884  0.570980  \n284803  0.012386 -1.016226 -0.606624 -0.395255  0.066230 -0.052144  3.249987  \n284804 -0.036815  0.640134  0.265745 -0.087371  0.004445 -0.026214  4.232366  \n284805 -0.151259  0.123205 -0.569159  0.546668  0.103297  0.099422  2.397895  \n284806  0.319745  0.008797 -0.473649 -0.818267 -0.002412  0.013557  5.384495  \n\n[284807 rows x 30 columns]\n</pre> In\u00a0[\u00a0]: Copied! <pre># Initialize the Isolation Forest\niso_forest = IsolationForest(contamination=0.05, random_state=101)   # high contamination to catch more fraud transactions\n\n# Fit the model and predict (returns -1 for anomalies and 1 for normal data)\niso_preds = iso_forest.fit_predict(X_scaled)\n\n# Convert -1 (anomalies) to 1 (fraud) and 1 (normal) to 0 (non-fraud)\niso_preds = [1 if x == -1 else 0 for x in iso_preds]\n\n# Evaluate the results\nprint(classification_report(y, iso_preds, digits=4))\nroc_auc_iso = roc_auc_score(y, iso_preds)\nprint(f\"ROC AUC Score:, {roc_auc_iso:.5f}\")\n</pre> # Initialize the Isolation Forest iso_forest = IsolationForest(contamination=0.05, random_state=101)   # high contamination to catch more fraud transactions  # Fit the model and predict (returns -1 for anomalies and 1 for normal data) iso_preds = iso_forest.fit_predict(X_scaled)  # Convert -1 (anomalies) to 1 (fraud) and 1 (normal) to 0 (non-fraud) iso_preds = [1 if x == -1 else 0 for x in iso_preds]  # Evaluate the results print(classification_report(y, iso_preds, digits=4)) roc_auc_iso = roc_auc_score(y, iso_preds) print(f\"ROC AUC Score:, {roc_auc_iso:.5f}\") <pre>              precision    recall  f1-score   support\n\n           0     0.9997    0.9514    0.9750    284315\n           1     0.0294    0.8516    0.0569       492\n\n    accuracy                         0.9512    284807\n   macro avg     0.5146    0.9015    0.5159    284807\nweighted avg     0.9981    0.9512    0.9734    284807\n\nROC AUC Score:, 0.90151\n</pre> In\u00a0[\u00a0]: Copied! <pre># Plot the confusion matrix\ncm = confusion_matrix(y, iso_preds)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, cmap = \"icefire\", fmt='g')\n\n# Add labels, title, and axis ticks\nplt.title('Confusion Matrix ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.show()\n</pre> # Plot the confusion matrix cm = confusion_matrix(y, iso_preds) plt.figure(figsize=(6, 4)) sns.heatmap(cm, annot=True, cmap = \"icefire\", fmt='g')  # Add labels, title, and axis ticks plt.title('Confusion Matrix ') plt.xlabel('Predicted') plt.ylabel('Actual') plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.show() In\u00a0[\u00a0]: Copied! <pre># Get anomaly scores (the lower, the more anomalous)\niso_scores = -iso_forest.decision_function(X_scaled)\n</pre> # Get anomaly scores (the lower, the more anomalous) iso_scores = -iso_forest.decision_function(X_scaled) In\u00a0[\u00a0]: Copied! <pre># Compute ROC curve and AUC\nfpr, tpr, thresholds = roc_curve(y, iso_scores)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve \u2013 Isolation Forest Fraud Detection', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n\n# Also print ROC AUC using the raw scores\nroc_auc_score_value = roc_auc_score(y, iso_scores)\nprint(\"ROC AUC (using anomaly scores):\", roc_auc_score_value)\n</pre> # Compute ROC curve and AUC fpr, tpr, thresholds = roc_curve(y, iso_scores) roc_auc = auc(fpr, tpr)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})') plt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve \u2013 Isolation Forest Fraud Detection', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show()  # Also print ROC AUC using the raw scores roc_auc_score_value = roc_auc_score(y, iso_scores) print(\"ROC AUC (using anomaly scores):\", roc_auc_score_value) <pre>ROC AUC (using anomaly scores): 0.9538343406753274\n</pre> <p>The Isolation Forest is the best model that takes a short amount of time while achieving high overall accuracy (95.12%) and a strong ROC AUC (0.90151). Thereby, this model is generally good at distinguishing fraudulent from normal transactions. However, although the overall performance of this unsupervised method is most effective compared to other anomaly detection techniques, there is still a generous number of false negatives and positives. The detection of this model, therefore, should be an input to support the bigger hybrid model for fraud detection, or it would need post-filter or secondary validation to reduce false positives.</p> In\u00a0[\u00a0]: Copied! <pre># Initialize One-Class SVM\noc_svm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.05)\n\n# Fit the model and predict (returns -1 for anomalies and 1 for normal data)\nsvm_preds = oc_svm.fit_predict(X_scaled)\n\n# Convert -1 (anomalies) to 1 (fraud) and 1 (normal) to 0 (non-fraud)\nsvm_preds = [1 if x == -1 else 0 for x in svm_preds]\n\n# Evaluate the results\nprint(classification_report(y, svm_preds, digits=4))\nroc_auc_svm = roc_auc_score(y, svm_preds)\nprint(f\"ROC AUC Score:, {roc_auc_svm:.5f}\") #CH\u1ed6 N\u00c0Y\nprint(\"Confusion Matrix:\")\n</pre> # Initialize One-Class SVM oc_svm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.05)  # Fit the model and predict (returns -1 for anomalies and 1 for normal data) svm_preds = oc_svm.fit_predict(X_scaled)  # Convert -1 (anomalies) to 1 (fraud) and 1 (normal) to 0 (non-fraud) svm_preds = [1 if x == -1 else 0 for x in svm_preds]  # Evaluate the results print(classification_report(y, svm_preds, digits=4)) roc_auc_svm = roc_auc_score(y, svm_preds) print(f\"ROC AUC Score:, {roc_auc_svm:.5f}\") #CH\u1ed6 N\u00c0Y print(\"Confusion Matrix:\")  <pre>              precision    recall  f1-score   support\n\n           0     0.9997    0.9514    0.9750    284315\n           1     0.0293    0.8496    0.0567       492\n\n    accuracy                         0.9512    284807\n   macro avg     0.5145    0.9005    0.5158    284807\nweighted avg     0.9981    0.9512    0.9734    284807\n\nROC AUC Score:, 0.90048\nConfusion Matrix:\n</pre> In\u00a0[\u00a0]: Copied! <pre># Plot the confusion matrix\ncm = confusion_matrix(y, svm_preds)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, cmap = \"icefire\", fmt='g')\n\n# Add labels, title, and axis ticks\nplt.title('Confusion Matrix ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.show()\n</pre> # Plot the confusion matrix cm = confusion_matrix(y, svm_preds) plt.figure(figsize=(6, 4)) sns.heatmap(cm, annot=True, cmap = \"icefire\", fmt='g')  # Add labels, title, and axis ticks plt.title('Confusion Matrix ') plt.xlabel('Predicted') plt.ylabel('Actual') plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.show() In\u00a0[\u00a0]: Copied! <pre># Get continuous anomaly scores from the SVM\n# Higher scores \u2192 more normal; lower \u2192 more anomalous\nsvm_scores = -oc_svm.decision_function(X_scaled)  # negate to align higher = more likely fraud\n\n# Compute ROC curve and AUC\nfpr, tpr, thresholds = roc_curve(y, svm_scores)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve \u2013 One-Class SVM Fraud Detection', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n\n# Optional: print ROC AUC using continuous scores\nroc_auc_score_value = roc_auc_score(y, svm_scores)\nprint(\"ROC AUC (using continuous scores):\", roc_auc_score_value)\n</pre> # Get continuous anomaly scores from the SVM # Higher scores \u2192 more normal; lower \u2192 more anomalous svm_scores = -oc_svm.decision_function(X_scaled)  # negate to align higher = more likely fraud  # Compute ROC curve and AUC fpr, tpr, thresholds = roc_curve(y, svm_scores) roc_auc = auc(fpr, tpr)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})') plt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve \u2013 One-Class SVM Fraud Detection', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show()  # Optional: print ROC AUC using continuous scores roc_auc_score_value = roc_auc_score(y, svm_scores) print(\"ROC AUC (using continuous scores):\", roc_auc_score_value) <pre>ROC AUC (using continuous scores): 0.9458170822497489\n</pre> <p>One-class SVM shows similar patterns recall with Isolation Forest (0.9458) but having a slightly worse performance; furthermore, its time-consuming nature may limit its practical application in real-time fraud detection systems</p> In\u00a0[\u00a0]: Copied! <pre># Initialize Local Outlier Factor (LOF)\nlof = LocalOutlierFactor(n_neighbors=10, contamination=0.05)\n\n# Predict (returns -1 for anomalies and 1 for normal data)\nlof_preds = lof.fit_predict(X_scaled)\n\n# Convert -1 (anomalies) to 1 (fraud) and 1 (normal) to 0 (non-fraud)\nlof_preds = [1 if x == -1 else 0 for x in lof_preds]\n\n# Evaluate the results\nprint(classification_report(y, lof_preds, digits=4))\nroc_auc_lof = roc_auc_score(y, lof_preds)\nprint(f\"ROC AUC Score:, {roc_auc_lof:.5f}\") #CH\u1ed6 N\u00c0Y\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y, lof_preds))\n</pre> # Initialize Local Outlier Factor (LOF) lof = LocalOutlierFactor(n_neighbors=10, contamination=0.05)  # Predict (returns -1 for anomalies and 1 for normal data) lof_preds = lof.fit_predict(X_scaled)  # Convert -1 (anomalies) to 1 (fraud) and 1 (normal) to 0 (non-fraud) lof_preds = [1 if x == -1 else 0 for x in lof_preds]  # Evaluate the results print(classification_report(y, lof_preds, digits=4)) roc_auc_lof = roc_auc_score(y, lof_preds) print(f\"ROC AUC Score:, {roc_auc_lof:.5f}\") #CH\u1ed6 N\u00c0Y print(\"Confusion Matrix:\") print(confusion_matrix(y, lof_preds)) <pre>              precision    recall  f1-score   support\n\n           0     0.9983    0.9500    0.9736    284315\n           1     0.0025    0.0711    0.0048       492\n\n    accuracy                         0.9485    284807\n   macro avg     0.5004    0.5106    0.4892    284807\nweighted avg     0.9966    0.9485    0.9719    284807\n\nROC AUC Score:, 0.51059\nConfusion Matrix:\n[[270109  14206]\n [   457     35]]\n</pre> In\u00a0[\u00a0]: Copied! <pre># Plot the confusion matrix\ncm = confusion_matrix(y, lof_preds)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, cmap = \"icefire\", fmt='g')\n\n# Add labels, title, and axis ticks\nplt.title('Confusion Matrix ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.show()\n</pre> # Plot the confusion matrix cm = confusion_matrix(y, lof_preds) plt.figure(figsize=(6, 4)) sns.heatmap(cm, annot=True, cmap = \"icefire\", fmt='g')  # Add labels, title, and axis ticks plt.title('Confusion Matrix ') plt.xlabel('Predicted') plt.ylabel('Actual') plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.show() In\u00a0[\u00a0]: Copied! <pre># Get anomaly scores (higher = more anomalous)\nlof_scores = -lof.negative_outlier_factor_\n\n# Compute ROC curve and AUC\nfpr, tpr, thresholds = roc_curve(y, lof_scores)\nroc_auc = roc_auc_score(y, lof_scores)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve - Local Outlier Factor', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n\n# Optional: print ROC AUC using continuous scores\nroc_auc_score_value = roc_auc_score(y, lof_scores)\nprint(\"ROC AUC (using continuous scores):\", roc_auc_score_value)\n</pre> # Get anomaly scores (higher = more anomalous) lof_scores = -lof.negative_outlier_factor_  # Compute ROC curve and AUC fpr, tpr, thresholds = roc_curve(y, lof_scores) roc_auc = roc_auc_score(y, lof_scores)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})') plt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve - Local Outlier Factor', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show()  # Optional: print ROC AUC using continuous scores roc_auc_score_value = roc_auc_score(y, lof_scores) print(\"ROC AUC (using continuous scores):\", roc_auc_score_value) <pre>ROC AUC (using continuous scores): 0.46234609814575006\n</pre> <p>Local Outlier Factor is the worst anomaly detection algorithm since it can only recall 7.11% fraud transactions (detected 35/ 492 fraud transactions), while having more false negatives and positives than Isolation Forest and One Class SVM. This might be because the credit set is highly imbalanced with high dimensionality. Thus, the local density approach fails to distinguish rare frauds from dense normal clusters, leading to very low recall. Overall, the outcome of LOF is even worse than a random guess, as it is shown in the ROC Curve figure.</p> In\u00a0[\u00a0]: Copied! <pre># Define the autoencoder model\ndef build_autoencoder(input_dim):\n    input_layer = Input(shape=(input_dim,))\n\n      # Encoder\n    encoded = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(input_layer)\n    encoded = Dropout(0.2)(encoded)\n    encoded = Dense(16, activation='relu', kernel_regularizer=l2(0.001))(encoded)\n    encoded = Dense(8, activation='relu', kernel_regularizer=l2(0.001))(encoded)\n\n  # Latent space\n    latent = Dense(4, activation='relu')(encoded)\n\n# Decoder\n    decoded = Dense(8, activation='relu', kernel_regularizer=l2(0.001))(latent)\n    decoded = Dropout(0.2)(decoded)\n    decoded = Dense(16, activation='relu', kernel_regularizer=l2(0.001))(decoded)\n    decoded = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(decoded)\n    output_layer = Dense(input_dim, activation='linear')(decoded)\n\n    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n    return autoencoder\n</pre> # Define the autoencoder model def build_autoencoder(input_dim):     input_layer = Input(shape=(input_dim,))        # Encoder     encoded = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(input_layer)     encoded = Dropout(0.2)(encoded)     encoded = Dense(16, activation='relu', kernel_regularizer=l2(0.001))(encoded)     encoded = Dense(8, activation='relu', kernel_regularizer=l2(0.001))(encoded)    # Latent space     latent = Dense(4, activation='relu')(encoded)  # Decoder     decoded = Dense(8, activation='relu', kernel_regularizer=l2(0.001))(latent)     decoded = Dropout(0.2)(decoded)     decoded = Dense(16, activation='relu', kernel_regularizer=l2(0.001))(decoded)     decoded = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(decoded)     output_layer = Dense(input_dim, activation='linear')(decoded)      autoencoder = Model(inputs=input_layer, outputs=output_layer)     return autoencoder In\u00a0[\u00a0]: Copied! <pre># Build and compile the model\nautoencoder = build_autoencoder(X_scaled.shape[1])\nautoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n\n# Train the model on normal transactions (non-fraudulent class, y == 0)\nX_train = X_scaled[y == 0]\nautoencoder.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=True, validation_split=0.1)\n\n#Train on only the normal transaction data (y==0) to learn \"normal behaviors, normal features\" of the non-fraud transaction\n\n# Calculate reconstruction error for all transactions\nreconstructed = autoencoder.predict(X_scaled)\nae_mse = np.mean(np.power(X_scaled - reconstructed, 2), axis=1)\n\n# Set a threshold for anomaly detection\nthreshold = np.percentile(ae_mse, 90)  # Adjust threshold (90th percentile)\nautoen_preds = np.where(ae_mse &gt; threshold, 1, 0)  # 1: anomaly (fraud), 0: normal\n\n# Evaluate the model\nprint(classification_report(y, autoen_preds, digits=4))\nroc_auc_ae = roc_auc_score(y, autoen_preds)\nprint(f\"ROC AUC Score:, {roc_auc_ae:.5f}\")\n</pre> # Build and compile the model autoencoder = build_autoencoder(X_scaled.shape[1]) autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')  # Train the model on normal transactions (non-fraudulent class, y == 0) X_train = X_scaled[y == 0] autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=True, validation_split=0.1)  #Train on only the normal transaction data (y==0) to learn \"normal behaviors, normal features\" of the non-fraud transaction  # Calculate reconstruction error for all transactions reconstructed = autoencoder.predict(X_scaled) ae_mse = np.mean(np.power(X_scaled - reconstructed, 2), axis=1)  # Set a threshold for anomaly detection threshold = np.percentile(ae_mse, 90)  # Adjust threshold (90th percentile) autoen_preds = np.where(ae_mse &gt; threshold, 1, 0)  # 1: anomaly (fraud), 0: normal  # Evaluate the model print(classification_report(y, autoen_preds, digits=4)) roc_auc_ae = roc_auc_score(y, autoen_preds) print(f\"ROC AUC Score:, {roc_auc_ae:.5f}\") <pre>Epoch 1/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 65s 7ms/step - loss: 0.0393 - val_loss: 0.0136\nEpoch 2/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 81s 7ms/step - loss: 0.0088 - val_loss: 0.0131\nEpoch 3/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 55s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 4/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56s 7ms/step - loss: 0.0087 - val_loss: 0.0134\nEpoch 5/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56s 7ms/step - loss: 0.0087 - val_loss: 0.0131\nEpoch 6/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 53s 7ms/step - loss: 0.0087 - val_loss: 0.0131\nEpoch 7/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 8/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 55s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 9/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 10/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 54s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 11/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56s 7ms/step - loss: 0.0087 - val_loss: 0.0131\nEpoch 12/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 82s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 13/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 55s 7ms/step - loss: 0.0087 - val_loss: 0.0134\nEpoch 14/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 58s 7ms/step - loss: 0.0087 - val_loss: 0.0131\nEpoch 15/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 59s 7ms/step - loss: 0.0087 - val_loss: 0.0135\nEpoch 16/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 82s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 17/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 58s 7ms/step - loss: 0.0087 - val_loss: 0.0134\nEpoch 18/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 19/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 82s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 20/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 58s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 21/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 59s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 22/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 58s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 23/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 59s 7ms/step - loss: 0.0087 - val_loss: 0.0134\nEpoch 24/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 61s 8ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 25/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 26/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 58s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 27/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 7ms/step - loss: 0.0087 - val_loss: 0.0131\nEpoch 28/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 29/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 7ms/step - loss: 0.0087 - val_loss: 0.0134\nEpoch 30/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56s 7ms/step - loss: 0.0087 - val_loss: 0.0131\nEpoch 31/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 32/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 59s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 33/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 82s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 34/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 63s 8ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 35/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 79s 8ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 36/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 76s 7ms/step - loss: 0.0087 - val_loss: 0.0131\nEpoch 37/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 54s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 38/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 55s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 39/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 55s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 40/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 54s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 41/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 53s 7ms/step - loss: 0.0087 - val_loss: 0.0134\nEpoch 42/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 43/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 53s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 44/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 87s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 45/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 55s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 46/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 58s 7ms/step - loss: 0.0087 - val_loss: 0.0133\nEpoch 47/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 80s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 48/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 82s 7ms/step - loss: 0.0087 - val_loss: 0.0134\nEpoch 49/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57s 7ms/step - loss: 0.0087 - val_loss: 0.0132\nEpoch 50/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 5ms/step - loss: 0.0087 - val_loss: 0.0132\n8901/8901 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 22s 2ms/step\n              precision    recall  f1-score   support\n\n           0     0.9998    0.9014    0.9480    284315\n           1     0.0153    0.8862    0.0301       492\n\n    accuracy                         0.9013    284807\n   macro avg     0.5075    0.8938    0.4891    284807\nweighted avg     0.9981    0.9013    0.9464    284807\n\nROC AUC Score:, 0.89377\n</pre> In\u00a0[\u00a0]: Copied! <pre># Plot the confusion matrix\ncm = confusion_matrix(y, autoen_preds)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, cmap=\"icefire\", fmt='g')\n\n# Add labels, title, and axis ticks\nplt.title('Confusion Matrix ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.show()\n</pre> # Plot the confusion matrix cm = confusion_matrix(y, autoen_preds) plt.figure(figsize=(6, 4)) sns.heatmap(cm, annot=True, cmap=\"icefire\", fmt='g')  # Add labels, title, and axis ticks plt.title('Confusion Matrix ') plt.xlabel('Predicted') plt.ylabel('Actual') plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.show() In\u00a0[\u00a0]: Copied! <pre># Use reconstruction errors (MSE) as continuous anomaly scores\nfpr, tpr, thresholds = roc_curve(y, ae_mse)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve \u2013 Autoencoder Fraud Detection', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Use reconstruction errors (MSE) as continuous anomaly scores fpr, tpr, thresholds = roc_curve(y, ae_mse) roc_auc = auc(fpr, tpr)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})') plt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve \u2013 Autoencoder Fraud Detection', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show() In\u00a0[\u00a0]: Copied! <pre># Features that want to keep\ncols_to_keep = ['V1', 'V3', 'V4', 'V7', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18']\n\n# Z with high-correlated features\nZ = X[cols_to_keep]\n\n# Print Z\nprint(Z.head())\n</pre> # Features that want to keep cols_to_keep = ['V1', 'V3', 'V4', 'V7', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18']  # Z with high-correlated features Z = X[cols_to_keep]  # Print Z print(Z.head()) <pre>         V1        V3        V4        V7       V10       V11       V12  \\\n0 -0.858580  1.263094  1.378155  0.214788  0.086906 -0.551600 -0.481068   \n1  0.784749  0.153991  0.448154 -0.075852 -0.154414  1.612727  0.725244   \n2 -0.857964  1.020005  0.379780  0.583031  0.188670  0.624501  0.063992   \n3 -0.676139  1.027114 -0.863291  0.213181 -0.053495 -0.226487  0.164012   \n4 -0.769290  0.935590  0.403034  0.465582  0.561371 -0.822843  0.430610   \n\n        V14       V16       V17       V18  \n0 -0.270919 -0.385535  0.188942  0.025791  \n1 -0.134332  0.381116 -0.108679 -0.183361  \n2 -0.153533 -1.358431  0.746673 -0.121359  \n3 -0.253031 -0.722535 -0.521227  1.965775  \n4 -0.751260 -0.372562 -0.212716 -0.038195  \n</pre> In\u00a0[\u00a0]: Copied! <pre># Standardize the data\nZ_scaled = scaler.fit_transform(Z)\n</pre> # Standardize the data Z_scaled = scaler.fit_transform(Z) In\u00a0[\u00a0]: Copied! <pre># Initialize the Isolation Forest\niso_forest_imp = IsolationForest(contamination=0.05, random_state=101)   # high contamination to catch more fraud transactions\n\n# Fit the model and predict (returns -1 for anomalies and 1 for normal data)\niso_imp_preds = iso_forest_imp.fit_predict(Z_scaled)\n\n# Convert -1 (anomalies) to 1 (fraud) and 1 (normal) to 0 (non-fraud)\niso_imp_preds = [1 if x == -1 else 0 for x in iso_imp_preds]\n\n# Evaluate the results\nprint(classification_report(y, iso_imp_preds, digits=4))\nroc_imp_auc = roc_auc_score(y, iso_imp_preds)\nprint(f\"ROC AUC Score: {roc_imp_auc:.5f}\") #CH\u1ed6 N\u00c0Y\n</pre> # Initialize the Isolation Forest iso_forest_imp = IsolationForest(contamination=0.05, random_state=101)   # high contamination to catch more fraud transactions  # Fit the model and predict (returns -1 for anomalies and 1 for normal data) iso_imp_preds = iso_forest_imp.fit_predict(Z_scaled)  # Convert -1 (anomalies) to 1 (fraud) and 1 (normal) to 0 (non-fraud) iso_imp_preds = [1 if x == -1 else 0 for x in iso_imp_preds]  # Evaluate the results print(classification_report(y, iso_imp_preds, digits=4)) roc_imp_auc = roc_auc_score(y, iso_imp_preds) print(f\"ROC AUC Score: {roc_imp_auc:.5f}\") #CH\u1ed6 N\u00c0Y  <pre>              precision    recall  f1-score   support\n\n           0     0.9998    0.9515    0.9750    284315\n           1     0.0310    0.8963    0.0599       492\n\n    accuracy                         0.9514    284807\n   macro avg     0.5154    0.9239    0.5175    284807\nweighted avg     0.9981    0.9514    0.9735    284807\n\nROC AUC Score:, 0.92390\n</pre> In\u00a0[\u00a0]: Copied! <pre># Plot the confusion matrix\ncm = confusion_matrix(y, iso_imp_preds)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, cmap = \"icefire\", fmt='g')\n\n# Add labels, title, and axis ticks\nplt.title('Confusion Matrix ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.show()\n</pre> # Plot the confusion matrix cm = confusion_matrix(y, iso_imp_preds) plt.figure(figsize=(6, 4)) sns.heatmap(cm, annot=True, cmap = \"icefire\", fmt='g')  # Add labels, title, and axis ticks plt.title('Confusion Matrix ') plt.xlabel('Predicted') plt.ylabel('Actual') plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.show() In\u00a0[\u00a0]: Copied! <pre># Get anomaly scores (the lower, the more anomalous)\niso_imp_scores = -iso_forest_imp.decision_function(Z_scaled)\n</pre> # Get anomaly scores (the lower, the more anomalous) iso_imp_scores = -iso_forest_imp.decision_function(Z_scaled) In\u00a0[\u00a0]: Copied! <pre># Compute ROC curve and AUC\nfpr, tpr, thresholds = roc_curve(y, iso_imp_scores)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve \u2013 Isolation Forest Fraud Detection - Important Features', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n\n# Also print ROC AUC using the raw scores\nroc_auc_score_value = roc_auc_score(y, iso_imp_scores)\nprint(\"ROC AUC (using anomaly scores):\", roc_auc_score_value)\n</pre> # Compute ROC curve and AUC fpr, tpr, thresholds = roc_curve(y, iso_imp_scores) roc_auc = auc(fpr, tpr)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})') plt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve \u2013 Isolation Forest Fraud Detection - Important Features', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show()  # Also print ROC AUC using the raw scores roc_auc_score_value = roc_auc_score(y, iso_imp_scores) print(\"ROC AUC (using anomaly scores):\", roc_auc_score_value) <pre>ROC AUC (using anomaly scores): 0.9609644075354986\n</pre> <p>This method achieved higher recall for fraudulent transactions, increasing to 0.9610. The F1-scores for the fraud class also improved slightly for Isolation Forest, reflecting a better balance between identifying frauds and limiting the number of false positives</p> In\u00a0[\u00a0]: Copied! <pre># Build and compile the model\nautoencoder_imp = build_autoencoder(Z_scaled.shape[1])\nautoencoder_imp.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n\n# Train the model on normal transactions (non-fraudulent class, y == 0)\nZ_train = Z_scaled[y == 0]\nautoencoder_imp.fit(Z_train, Z_train, epochs=50, batch_size=32, shuffle=True, validation_split=0.1)\n\n#Train on only the normal transaction data (y==0) to learn \"normal behaviors, normal features\" of the non-fraud transaction\n\n# Calculate reconstruction error for all transactions\nreconstructed_imp = autoencoder_imp.predict(Z_scaled)\nae_mse_imp = np.mean(np.power(Z_scaled - reconstructed_imp, 2), axis=1)\n\n# Set a threshold for anomaly detection\nthreshold = np.percentile(ae_mse_imp, 90)  # Adjust threshold (90th percentile)\nautoen_imp_preds = np.where(ae_mse_imp &gt; threshold, 1, 0)  # 1: anomaly (fraud), 0: normal\n\n# Evaluate the model\nprint(classification_report(y, autoen_imp_preds, digits=4))  #CH\u1ed6 N\u00c0Y\nroc_auc_ae_imp = roc_auc_score(y, autoen_imp_preds)\nprint(f\"ROC AUC Score: {roc_auc_ae_imp:.5f}\") #CH\u1ed6 N\u00c0Y\n</pre> # Build and compile the model autoencoder_imp = build_autoencoder(Z_scaled.shape[1]) autoencoder_imp.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')  # Train the model on normal transactions (non-fraudulent class, y == 0) Z_train = Z_scaled[y == 0] autoencoder_imp.fit(Z_train, Z_train, epochs=50, batch_size=32, shuffle=True, validation_split=0.1)  #Train on only the normal transaction data (y==0) to learn \"normal behaviors, normal features\" of the non-fraud transaction  # Calculate reconstruction error for all transactions reconstructed_imp = autoencoder_imp.predict(Z_scaled) ae_mse_imp = np.mean(np.power(Z_scaled - reconstructed_imp, 2), axis=1)  # Set a threshold for anomaly detection threshold = np.percentile(ae_mse_imp, 90)  # Adjust threshold (90th percentile) autoen_imp_preds = np.where(ae_mse_imp &gt; threshold, 1, 0)  # 1: anomaly (fraud), 0: normal  # Evaluate the model print(classification_report(y, autoen_imp_preds, digits=4))  #CH\u1ed6 N\u00c0Y roc_auc_ae_imp = roc_auc_score(y, autoen_imp_preds) print(f\"ROC AUC Score: {roc_auc_ae_imp:.5f}\") #CH\u1ed6 N\u00c0Y <pre>Epoch 1/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45s 5ms/step - loss: 0.0411 - val_loss: 0.0111\nEpoch 2/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 42s 5ms/step - loss: 0.0097 - val_loss: 0.0097\nEpoch 3/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 4/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 37s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 5/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 5ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 6/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 37s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 7/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 42s 5ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 8/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 41s 5ms/step - loss: 0.0095 - val_loss: 0.0096\nEpoch 9/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 38s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 10/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 34s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 11/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 47s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 12/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35s 4ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 13/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 14/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 37s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 15/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 16/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 17/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 18/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 38s 5ms/step - loss: 0.0095 - val_loss: 0.0096\nEpoch 19/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 37s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 20/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 41s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 21/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 34s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 22/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 23/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39s 5ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 24/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 37s 5ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 25/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 36s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 26/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 27/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 28/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 34s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 29/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 30/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 38s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 31/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35s 4ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 32/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 42s 4ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 33/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 34/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 5ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 35/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 38s 5ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 36/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 37/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 40s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 38/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 38s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 39/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 41s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 40/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45s 6ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 41/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 42s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 42/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 41s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 43/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44s 6ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 44/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 42s 5ms/step - loss: 0.0095 - val_loss: 0.0098\nEpoch 45/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 43s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 46/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 43s 5ms/step - loss: 0.0095 - val_loss: 0.0096\nEpoch 47/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45s 6ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 48/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45s 6ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 49/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 43s 5ms/step - loss: 0.0095 - val_loss: 0.0097\nEpoch 50/50\n7997/7997 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 45s 6ms/step - loss: 0.0095 - val_loss: 0.0097\n8901/8901 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23s 3ms/step\n              precision    recall  f1-score   support\n\n           0     0.9998    0.9014    0.9481    284315\n           1     0.0157    0.9085    0.0309       492\n\n    accuracy                         0.9014    284807\n   macro avg     0.5078    0.9050    0.4895    284807\nweighted avg     0.9981    0.9014    0.9465    284807\n\nROC AUC Score:, 0.90497\n</pre> In\u00a0[\u00a0]: Copied! <pre># Plot the confusion matrix\ncm = confusion_matrix(y, autoen_imp_preds)\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, cmap=\"icefire\", fmt='g')\n\n# Add labels, title, and axis ticks\nplt.title('Confusion Matrix ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.show()\n</pre> # Plot the confusion matrix cm = confusion_matrix(y, autoen_imp_preds) plt.figure(figsize=(6, 4)) sns.heatmap(cm, annot=True, cmap=\"icefire\", fmt='g')  # Add labels, title, and axis ticks plt.title('Confusion Matrix ') plt.xlabel('Predicted') plt.ylabel('Actual') plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.show() In\u00a0[\u00a0]: Copied! <pre># Use reconstruction errors (MSE) as continuous anomaly scores\nfpr, tpr, thresholds = roc_curve(y, ae_mse_imp)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve \u2013 Autoencoder Fraud Detection', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Use reconstruction errors (MSE) as continuous anomaly scores fpr, tpr, thresholds = roc_curve(y, ae_mse_imp) roc_auc = auc(fpr, tpr)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})') plt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve \u2013 Autoencoder Fraud Detection', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show() <p>Machine Learning Fraud detection is a binary classification task in which any transaction will be predicted and labeled as a fraud or legit. Different machine learning algorithms are tested and analysed.</p> <ul> <li>RandomForestClassifier()</li> <li>XGBClassifier()</li> <li>LGBMClassifier()</li> <li>CatBoostClassifier()</li> <li>AdaBoostClassifier()</li> </ul> In\u00a0[\u00a0]: Copied! <pre>from collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\n</pre> from collections import Counter from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score from imblearn.over_sampling import SMOTE In\u00a0[\u00a0]: Copied! <pre>df2 = df.copy()\n</pre> df2 = df.copy() In\u00a0[\u00a0]: Copied! <pre>df2[\"ae_mse\"] = ae_mse\ndf2[\"iso_score\"] = iso_scores\n</pre> df2[\"ae_mse\"] = ae_mse df2[\"iso_score\"] = iso_scores In\u00a0[\u00a0]: Copied! <pre>df2.head()\n</pre> df2.head() Out[\u00a0]: Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V23 V24 V25 V26 V27 V28 Amount Class ae_mse iso_score 0 0.0 -1.359807 -0.072781 2.536347 1.378155 -0.338321 0.462388 0.239599 0.098698 0.363787 ... -0.110474 0.066928 0.128539 -0.189115 0.133558 -0.021053 149.62 0 0.013558 -0.095812 1 0.0 1.191857 0.266151 0.166480 0.448154 0.060018 -0.082361 -0.078803 0.085102 -0.255425 ... 0.101288 -0.339846 0.167170 0.125895 -0.008983 0.014724 2.69 0 0.011617 -0.096090 2 1.0 -1.358354 -1.340163 1.773209 0.379780 -0.503198 1.800499 0.791461 0.247676 -1.514654 ... 0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752 378.66 0 0.019915 -0.007239 3 1.0 -0.966272 -0.185226 1.792993 -0.863291 -0.010309 1.247203 0.237609 0.377436 -1.387024 ... -0.190321 -1.175575 0.647376 -0.221929 0.062723 0.061458 123.50 0 0.014506 -0.046854 4 2.0 -1.158233 0.877737 1.548718 0.403034 -0.407193 0.095921 0.592941 -0.270533 0.817739 ... -0.137458 0.141267 -0.206010 0.502292 0.219422 0.215153 69.99 0 0.013145 -0.067794 <p>5 rows \u00d7 33 columns</p> In\u00a0[\u00a0]: Copied! <pre># Define dataset\ndef Definedata(df2):\n    X_smote = df2.drop(columns=['Class']).values\n    y_smote = df2['Class'].values\n    return X_smote, y_smote\n</pre> # Define dataset def Definedata(df2):     X_smote = df2.drop(columns=['Class']).values     y_smote = df2['Class'].values     return X_smote, y_smote In\u00a0[\u00a0]: Copied! <pre>def ApplySMOTE(df2, test_size=0.5, random_state=2):\n    X_smote, y_smote = Definedata(df2)\n\n    # summarize class distribution\n    counter = Counter(y_smote)\n    print(\"Original class distribution:\", counter)\n\n    # apply SMOTE\n    smt = SMOTE(random_state=0)\n    X_res, y_res = smt.fit_resample(X_smote, y_smote)\n\n    # summarize new class distribution\n    counter_res = Counter(y_res)\n    print(\"After SMOTE class distribution:\", counter_res)\n\n    # split train/test\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_res, y_res, test_size=test_size, random_state=random_state\n    )\n\n    # optional: scatter plot for first 2 features\n    for label in np.unique(y_res):\n        row_ix = np.where(y_res == label)\n        plt.scatter(X_res[row_ix, 0], X_res[row_ix, 1], label=str(label))\n    plt.legend()\n    plt.title(\"SMOTE Data Distribution (first 2 features)\")\n    plt.show()\n\n    return X_train, X_test, y_train, y_test\n</pre> def ApplySMOTE(df2, test_size=0.5, random_state=2):     X_smote, y_smote = Definedata(df2)      # summarize class distribution     counter = Counter(y_smote)     print(\"Original class distribution:\", counter)      # apply SMOTE     smt = SMOTE(random_state=0)     X_res, y_res = smt.fit_resample(X_smote, y_smote)      # summarize new class distribution     counter_res = Counter(y_res)     print(\"After SMOTE class distribution:\", counter_res)      # split train/test     X_train, X_test, y_train, y_test = train_test_split(         X_res, y_res, test_size=test_size, random_state=random_state     )      # optional: scatter plot for first 2 features     for label in np.unique(y_res):         row_ix = np.where(y_res == label)         plt.scatter(X_res[row_ix, 0], X_res[row_ix, 1], label=str(label))     plt.legend()     plt.title(\"SMOTE Data Distribution (first 2 features)\")     plt.show()      return X_train, X_test, y_train, y_test In\u00a0[\u00a0]: Copied! <pre># Train model and plot confusion matrices\ndef Models(model, X_train, X_test, y_train, y_test, df2, title=\"Model\", cmap='icefire'):\n    # train model\n    model.fit(X_train, y_train)\n\n    # full dataset\n    X_all, y_all = Definedata(df2)\n\n    # confusion matrices\n    train_matrix = pd.crosstab(y_train, model.predict(X_train), rownames=['Actual'], colnames=['Predicted'])\n    test_matrix = pd.crosstab(y_test, model.predict(X_test), rownames=['Actual'], colnames=['Predicted'])\n    full_matrix = pd.crosstab(y_all, model.predict(X_all), rownames=['Actual'], colnames=['Predicted'])\n\n    # plot heatmaps\n    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(20, 4))\n\n    sns.heatmap(train_matrix, annot=True, fmt=\"d\", cbar=False, ax=ax1, cmap=cmap)\n    ax1.set_title(f\"{title} - Training Set\")\n    ax1.set_xlabel(f\"Accuracy: {accuracy_score(y_train, model.predict(X_train)):.4f}\")\n\n    sns.heatmap(test_matrix, annot=True, fmt=\"d\", cbar=False, ax=ax2, cmap=cmap)\n    ax2.set_title(f\"{title} - Testing Set\")\n    ax2.set_xlabel(f\"Accuracy: {accuracy_score(y_test, model.predict(X_test)):.4f}\")\n\n    sns.heatmap(full_matrix, annot=True, fmt=\"d\", cbar=False, ax=ax3, cmap=cmap)\n    ax3.set_title(f\"{title} - Full Dataset\")\n    ax3.set_xlabel(f\"Accuracy: {accuracy_score(y_all, model.predict(X_all)):.4f}\")\n\n    plt.show()\n\n    return model, model.predict(X_all)\n</pre> # Train model and plot confusion matrices def Models(model, X_train, X_test, y_train, y_test, df2, title=\"Model\", cmap='icefire'):     # train model     model.fit(X_train, y_train)      # full dataset     X_all, y_all = Definedata(df2)      # confusion matrices     train_matrix = pd.crosstab(y_train, model.predict(X_train), rownames=['Actual'], colnames=['Predicted'])     test_matrix = pd.crosstab(y_test, model.predict(X_test), rownames=['Actual'], colnames=['Predicted'])     full_matrix = pd.crosstab(y_all, model.predict(X_all), rownames=['Actual'], colnames=['Predicted'])      # plot heatmaps     f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(20, 4))      sns.heatmap(train_matrix, annot=True, fmt=\"d\", cbar=False, ax=ax1, cmap=cmap)     ax1.set_title(f\"{title} - Training Set\")     ax1.set_xlabel(f\"Accuracy: {accuracy_score(y_train, model.predict(X_train)):.4f}\")      sns.heatmap(test_matrix, annot=True, fmt=\"d\", cbar=False, ax=ax2, cmap=cmap)     ax2.set_title(f\"{title} - Testing Set\")     ax2.set_xlabel(f\"Accuracy: {accuracy_score(y_test, model.predict(X_test)):.4f}\")      sns.heatmap(full_matrix, annot=True, fmt=\"d\", cbar=False, ax=ax3, cmap=cmap)     ax3.set_title(f\"{title} - Full Dataset\")     ax3.set_xlabel(f\"Accuracy: {accuracy_score(y_all, model.predict(X_all)):.4f}\")      plt.show()      return model, model.predict(X_all) In\u00a0[\u00a0]: Copied! <pre># Feature importances\ndef FeatureImportances(model, X_train, y_train, df2):\n    # Fit model\n    model.fit(X_train, y_train)\n\n    # Feature importance\n    importances = model.feature_importances_\n    features = df2.drop(columns=['Class']).columns\n\n    # Create dataframe\n    imp = pd.DataFrame({'Feature': features, 'Importance': importances})\n\n    # Cumulative Importance\n    imp['Cumulative Importance'] = imp['Importance'].cumsum()\n\n    # Sort importance\n    imp = imp.sort_values(by='Importance', ascending = False).reset_index(drop=True)\n\n    return imp\n</pre> # Feature importances def FeatureImportances(model, X_train, y_train, df2):     # Fit model     model.fit(X_train, y_train)      # Feature importance     importances = model.feature_importances_     features = df2.drop(columns=['Class']).columns      # Create dataframe     imp = pd.DataFrame({'Feature': features, 'Importance': importances})      # Cumulative Importance     imp['Cumulative Importance'] = imp['Importance'].cumsum()      # Sort importance     imp = imp.sort_values(by='Importance', ascending = False).reset_index(drop=True)      return imp In\u00a0[\u00a0]: Copied! <pre># Apply SMOTE\nX_train, X_test, y_train, y_test = ApplySMOTE(df2)\n</pre> # Apply SMOTE X_train, X_test, y_train, y_test = ApplySMOTE(df2) <pre>Original class distribution: Counter({np.int64(0): 284315, np.int64(1): 492})\nAfter SMOTE class distribution: Counter({np.int64(0): 284315, np.int64(1): 284315})\n</pre> In\u00a0[\u00a0]: Copied! <pre># Train RandomForest model\nrf_model = RandomForestClassifier(random_state=0)\nmodel, y_pred = Models(rf_model, X_train, X_test, y_train, y_test, df2, title=\"RandomForest / SMOTE\")\n</pre> # Train RandomForest model rf_model = RandomForestClassifier(random_state=0) model, y_pred = Models(rf_model, X_train, X_test, y_train, y_test, df2, title=\"RandomForest / SMOTE\") In\u00a0[\u00a0]: Copied! <pre># Feature importances\nimp_df = FeatureImportances(rf_model, X_train, y_train, df2)\nprint(imp_df)\n</pre> # Feature importances imp_df = FeatureImportances(rf_model, X_train, y_train, df2) print(imp_df) <pre>      Feature  Importance  Cumulative Importance\n0         V14    0.186478               0.644383\n1      ae_mse    0.123098               0.906358\n2          V4    0.099900               0.168748\n3         V10    0.099189               0.340771\n4   iso_score    0.093642               1.000000\n5         V12    0.059304               0.453777\n6         V17    0.054582               0.733205\n7         V11    0.053702               0.394473\n8          V7    0.033926               0.210660\n9          V3    0.031128               0.068848\n10        V16    0.030692               0.678623\n11         V9    0.025590               0.241582\n12         V2    0.019039               0.037720\n13         V1    0.011340               0.018681\n14        V27    0.007494               0.774754\n15       Time    0.007341               0.007341\n16        V21    0.006410               0.751106\n17         V8    0.005333               0.215992\n18        V28    0.004891               0.779646\n19         V6    0.004831               0.176734\n20        V19    0.004685               0.741224\n21        V13    0.004128               0.457904\n22     Amount    0.003614               0.783260\n23        V26    0.003550               0.767260\n24        V15    0.003549               0.647932\n25        V20    0.003472               0.744696\n26        V18    0.003334               0.736539\n27        V23    0.003312               0.757445\n28        V25    0.003207               0.763710\n29         V5    0.003155               0.171903\n30        V24    0.003058               0.760503\n31        V22    0.003027               0.754133\n</pre> <p>After being trained and tested on the processed dataset, the Random Forest model is evaluated on the full original dataset. The result shows that the Random Forest model has successfully learned and can detect all the fraudulent transactions, with an accuracy equal to 99.99%. The confusion matrix shows that the model just has 32 false positives, a significantly smaller amount compared to other tested methods in this project. In addition, the model has 100% recall and ~94% precision, which means that the model is sensitive to fraudulent transactions.</p> <p>Furthermore, the dataset is heavily dominated by a few core components, which are V14, V10, V4, V12, V11, V16, V3, and V17. These are 8/11 highly correlated features that are mentioned in the EDA par; these features are principal components that reflect the strong variance related to fraud patterns. For this supervised model, these features account for over 82% of all importance.</p> In\u00a0[\u00a0]: Copied! <pre># Full dataset\nX_all, y_all = Definedata(df2)\n</pre> # Full dataset X_all, y_all = Definedata(df2) In\u00a0[\u00a0]: Copied! <pre># Classification report\nreport = classification_report(y_all, y_pred, digits=4)\nprint(\"Classification Report (Full Dataset)\")\nprint(report)\n\n# Get probabilities for the positive class (Class=1)\ny_proba_rf = rf_model.predict_proba(X_all)[:, 1]\n\n# ROC-AUC\nroc_auc_rf = roc_auc_score(y_all, y_proba_rf)\nprint(f\"ROC AUC Score (Full Dataset): {roc_auc_rf:.5f}\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_all, y_pred)\ncm_df2 = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],\n                     columns=[f\"Pred_{i}\" for i in range(cm.shape[1])])\nprint(\"Confusion Matrix (Full Dataset):\")\nprint(cm_df2)\n</pre> # Classification report report = classification_report(y_all, y_pred, digits=4) print(\"Classification Report (Full Dataset)\") print(report)  # Get probabilities for the positive class (Class=1) y_proba_rf = rf_model.predict_proba(X_all)[:, 1]  # ROC-AUC roc_auc_rf = roc_auc_score(y_all, y_proba_rf) print(f\"ROC AUC Score (Full Dataset): {roc_auc_rf:.5f}\")  # Confusion Matrix cm = confusion_matrix(y_all, y_pred) cm_df2 = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],                      columns=[f\"Pred_{i}\" for i in range(cm.shape[1])]) print(\"Confusion Matrix (Full Dataset):\") print(cm_df2)  <pre>Classification Report (Full Dataset)\n              precision    recall  f1-score   support\n\n           0     1.0000    0.9999    0.9999    284315\n           1     0.9425    1.0000    0.9704       492\n\n    accuracy                         0.9999    284807\n   macro avg     0.9713    0.9999    0.9852    284807\nweighted avg     0.9999    0.9999    0.9999    284807\n\nROC AUC Score (Full Dataset): 0.99999\nConfusion Matrix (Full Dataset):\n          Pred_0  Pred_1\nActual_0  284285      30\nActual_1       0     492\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculate ROC curve points\nfpr, tpr, thresholds = roc_curve(y_all, y_proba_rf)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_rf:.5f})')\nplt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve - Random Forest', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Calculate ROC curve points fpr, tpr, thresholds = roc_curve(y_all, y_proba_rf)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_rf:.5f})') plt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve - Random Forest', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show() In\u00a0[\u00a0]: Copied! <pre># Calculate Gini coefficient\ngini = 2 * roc_auc_rf - 1\nprint(f\"Gini Coefficient: {gini:.4f}\")\n</pre> # Calculate Gini coefficient gini = 2 * roc_auc_rf - 1 print(f\"Gini Coefficient: {gini:.4f}\") <pre>Gini Coefficient: 0.8970\n</pre> <p>The ROC Curve shows that the model has good performance, and with the Gini Coefficient (GINI) approximately 1.0000. The Random Forest has been proven to have an excellent performance</p> <p>Overall: The XGBoost is the second most effective supervised algorithm, which has successfully detected all the fraud transactions, but has 72 false positives, 1.25 times more than that of Random Forest. However, compared to other models, the performance of XGBoost is highly pleasing</p> In\u00a0[\u00a0]: Copied! <pre>!pip install xgboost\nfrom xgboost import XGBClassifier\n</pre> !pip install xgboost from xgboost import XGBClassifier <pre>Requirement already satisfied: xgboost in c:\\users\\hi\\anaconda3\\lib\\site-packages (3.1.0)\nRequirement already satisfied: numpy in c:\\users\\hi\\anaconda3\\lib\\site-packages (from xgboost) (2.3.4)\nRequirement already satisfied: scipy in c:\\users\\hi\\anaconda3\\lib\\site-packages (from xgboost) (1.16.3)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Train XGBoots model\nxgb_model = XGBClassifier(random_state=0)\nmodel, y_pred = Models(xgb_model, X_train, X_test, y_train, y_test, df2, title=\"XGBoot / SMOTE\")\n</pre> # Train XGBoots model xgb_model = XGBClassifier(random_state=0) model, y_pred = Models(xgb_model, X_train, X_test, y_train, y_test, df2, title=\"XGBoot / SMOTE\") In\u00a0[\u00a0]: Copied! <pre># Feature importances\nimp_df = FeatureImportances(xgb_model, X_train, y_train, df2)\nprint(imp_df)\n</pre> # Feature importances imp_df = FeatureImportances(xgb_model, X_train, y_train, df2) print(imp_df) <pre>      Feature  Importance  Cumulative Importance\n0         V14    0.675436               0.867148\n1          V4    0.051825               0.090891\n2         V12    0.037470               0.183024\n3         V17    0.031540               0.911074\n4          V3    0.017215               0.039066\n5          V8    0.015453               0.122891\n6   iso_score    0.013974               1.000000\n7          V1    0.010589               0.016512\n8         V10    0.009228               0.137271\n9         V13    0.008688               0.191712\n10     Amount    0.008466               0.978065\n11        V11    0.008283               0.145554\n12     ae_mse    0.007961               0.986026\n13        V19    0.007951               0.925579\n14        V23    0.007250               0.946593\n15         V6    0.007021               0.103200\n16        V16    0.006602               0.879534\n17        V18    0.006553               0.917627\n18        V28    0.006054               0.969599\n19       Time    0.005922               0.005922\n20        V15    0.005784               0.872932\n21        V26    0.005569               0.960341\n22        V25    0.005359               0.954772\n23         V2    0.005339               0.021851\n24         V5    0.005288               0.096179\n25         V9    0.005151               0.128042\n26        V21    0.004832               0.934595\n27        V22    0.004747               0.939342\n28         V7    0.004238               0.107438\n29        V20    0.004185               0.929763\n30        V27    0.003205               0.963546\n31        V24    0.002821               0.949413\n</pre> <p>The decision-making process of this model is largely driven by the top 4 components, including V14, V4, V1,2 and V17. These features account for approximately 90.7% of the feature importance. Among them, V14 stands out as the dominant predictor with an importance value of over 68.8%. It suggests that V14 carries substantial discriminative information that enables the model to effectively separate fraud transactions from the norm. The other features in the top four contribute moderately, with importance scores ranging between 0.03 and 0.05. However, these values are still higher than those of the remaining features, which have importance scores of 0.01 or lower.</p> In\u00a0[\u00a0]: Copied! <pre># Full dataset\nX_all, y_all = Definedata(df2)\n\n# Classification report\nreport = classification_report(y_all, y_pred, digits=4)\nprint(\"Classification Report (Full Dataset)\")\nprint(report)\n\n# Get probabilities for the positive class (Class=1)\ny_proba_xgb = xgb_model.predict_proba(X_all)[:, 1]\n\n# ROC-AUC\nroc_auc_xgb = roc_auc_score(y_all, y_proba_xgb)\nprint(f\"ROC AUC Score (Full Dataset): {roc_auc_xgb:.5f}\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_all, y_pred)\ncm_df = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],\n                     columns=[f\"Pred_{i}\" for i in range(cm.shape[1])])\nprint(\"Confusion Matrix (Full Dataset):\")\nprint(cm_df)\n</pre> # Full dataset X_all, y_all = Definedata(df2)  # Classification report report = classification_report(y_all, y_pred, digits=4) print(\"Classification Report (Full Dataset)\") print(report)  # Get probabilities for the positive class (Class=1) y_proba_xgb = xgb_model.predict_proba(X_all)[:, 1]  # ROC-AUC roc_auc_xgb = roc_auc_score(y_all, y_proba_xgb) print(f\"ROC AUC Score (Full Dataset): {roc_auc_xgb:.5f}\")  # Confusion Matrix cm = confusion_matrix(y_all, y_pred) cm_df = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],                      columns=[f\"Pred_{i}\" for i in range(cm.shape[1])]) print(\"Confusion Matrix (Full Dataset):\") print(cm_df)  <pre>Classification Report (Full Dataset)\n              precision    recall  f1-score   support\n\n           0     1.0000    0.9998    0.9999    284315\n           1     0.8911    0.9980    0.9415       492\n\n    accuracy                         0.9998    284807\n   macro avg     0.9456    0.9989    0.9707    284807\nweighted avg     0.9998    0.9998    0.9998    284807\n\nROC AUC Score (Full Dataset): 0.99998\nConfusion Matrix (Full Dataset):\n          Pred_0  Pred_1\nActual_0  284255      60\nActual_1       1     491\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculate ROC curve points\nfpr, tpr, thresholds = roc_curve(y_all, y_proba_xgb)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_xgb:.5f})')\nplt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve - XGBoosts', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Calculate ROC curve points fpr, tpr, thresholds = roc_curve(y_all, y_proba_xgb)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_xgb:.5f})') plt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve - XGBoosts', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show() In\u00a0[\u00a0]: Copied! <pre># Calculate Gini coefficient\ngini_xgb = 2 * roc_auc_xgb - 1\nprint(f\"Gini Coefficient of XGBoosts: {gini_xgb:.4f}\")\n</pre> # Calculate Gini coefficient gini_xgb = 2 * roc_auc_xgb - 1 print(f\"Gini Coefficient of XGBoosts: {gini_xgb:.4f}\") <pre>Gini Coefficient of XGBoosts: 1.0000\n</pre> <p>Similar to Random Forest, the ROC Curve of XGBoost model shows that the model has excellent performance, and with the Gini Coefficient (GINI) approximately 1.0000.</p> <p>Overall: CatBoost ranks as the third most effective supervised algorithm, demonstrating slightly lower performance compared to XGBoost. CatBoost achieves perfect recall for fraud transactions and a precision of 0.8586, with only a small number of false positives. Its F1-score of 0.9239 indicates strong overall performance.</p> In\u00a0[\u00a0]: Copied! <pre>!pip install catboost\nfrom catboost import CatBoostClassifier\n</pre> !pip install catboost from catboost import CatBoostClassifier <pre>Requirement already satisfied: catboost in c:\\users\\hi\\anaconda3\\lib\\site-packages (1.2.8)\nRequirement already satisfied: graphviz in c:\\users\\hi\\anaconda3\\lib\\site-packages (from catboost) (0.21)\nRequirement already satisfied: matplotlib in c:\\users\\hi\\anaconda3\\lib\\site-packages (from catboost) (3.10.0)\nRequirement already satisfied: numpy&lt;3.0,&gt;=1.16.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from catboost) (2.3.4)\nRequirement already satisfied: pandas&gt;=0.24 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from catboost) (2.2.3)\nRequirement already satisfied: scipy in c:\\users\\hi\\anaconda3\\lib\\site-packages (from catboost) (1.16.3)\nRequirement already satisfied: plotly in c:\\users\\hi\\anaconda3\\lib\\site-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in c:\\users\\hi\\anaconda3\\lib\\site-packages (from catboost) (1.17.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from pandas&gt;=0.24-&gt;catboost) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from pandas&gt;=0.24-&gt;catboost) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from pandas&gt;=0.24-&gt;catboost) (2025.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from matplotlib-&gt;catboost) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from matplotlib-&gt;catboost) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from matplotlib-&gt;catboost) (4.55.3)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from matplotlib-&gt;catboost) (1.4.8)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from matplotlib-&gt;catboost) (24.2)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from matplotlib-&gt;catboost) (11.1.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from matplotlib-&gt;catboost) (3.2.0)\nRequirement already satisfied: tenacity&gt;=6.2.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from plotly-&gt;catboost) (9.0.0)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Train CatBoost model\ncat_model = CatBoostClassifier(\n    iterations=500,\n    learning_rate=0.02,\n    depth=12,\n    eval_metric='AUC',\n    random_seed=42,\n    bagging_temperature=0.2,\n    od_type='Iter',\n    metric_period=100,\n    od_wait=100\n)\n\n# Fit model and make predictions (using your custom Models() function)\nmodel, y_pred = Models(cat_model, X_train, X_test, y_train, y_test, df2, title=\"CatBoost / SMOTE\")\n</pre> # Train CatBoost model cat_model = CatBoostClassifier(     iterations=500,     learning_rate=0.02,     depth=12,     eval_metric='AUC',     random_seed=42,     bagging_temperature=0.2,     od_type='Iter',     metric_period=100,     od_wait=100 )  # Fit model and make predictions (using your custom Models() function) model, y_pred = Models(cat_model, X_train, X_test, y_train, y_test, df2, title=\"CatBoost / SMOTE\")   <pre>0:\ttotal: 1.13s\tremaining: 9m 25s\n100:\ttotal: 1m 58s\tremaining: 7m 48s\n200:\ttotal: 3m 50s\tremaining: 5m 42s\n300:\ttotal: 5m 44s\tremaining: 3m 47s\n400:\ttotal: 7m 35s\tremaining: 1m 52s\n499:\ttotal: 9m 28s\tremaining: 0us\n</pre> In\u00a0[\u00a0]: Copied! <pre># Feature importances\nimp_df = FeatureImportances(cat_model, X_train, y_train, df2)\nprint(imp_df)\n</pre> # Feature importances imp_df = FeatureImportances(cat_model, X_train, y_train, df2) print(imp_df) <pre>0:\ttotal: 1.22s\tremaining: 10m 10s\n100:\ttotal: 2m 6s\tremaining: 8m 20s\n200:\ttotal: 4m 2s\tremaining: 6m\n300:\ttotal: 6m 7s\tremaining: 4m 3s\n400:\ttotal: 8m 14s\tremaining: 2m 1s\n499:\ttotal: 9m 24s\tremaining: 0us\n      Feature  Importance  Cumulative Importance\n0          V4    9.285580              27.129225\n1         V14    8.826556              61.416914\n2        Time    7.490655               7.490655\n3          V8    4.735935              38.536574\n4         V26    4.553163              90.966479\n5          V1    4.475881              11.966536\n6         V17    4.040739              71.119769\n7         V12    3.810937              50.369164\n8          V3    3.772851              17.843645\n9         V11    3.569059              46.558227\n10        V15    3.294565              64.711479\n11        V24    2.957956              83.802736\n12        V10    2.621294              42.989168\n13        V25    2.610580              86.413316\n14         V6    2.410979              31.442295\n15        V16    2.367550              67.079029\n16        V18    2.365521              73.485289\n17         V7    2.358343              33.800639\n18     ae_mse    2.354068              97.737994\n19  iso_score    2.262006             100.000000\n20        V13    2.221195              52.590358\n21         V2    2.104257              14.070793\n22        V28    2.042107              94.041987\n23         V5    1.902091              29.031316\n24         V9    1.831300              40.367874\n25        V22    1.825431              79.028086\n26        V23    1.816694              80.844780\n27        V19    1.565177              75.050466\n28     Amount    1.341939              95.383926\n29        V21    1.126434              77.202654\n30        V27    1.033400              91.999880\n31        V20    1.025754              76.076220\n</pre> In\u00a0[\u00a0]: Copied! <pre># Full dataset\nX_all, y_all = Definedata(df2)\n\n# Classification report\nreport = classification_report(y_all, y_pred, digits=4)\nprint(\"=== Classification Report on Full Dataset ===\")\nprint(report)\n\n# Get probabilities for the positive class (Class=1)\ny_proba_cat = cat_model.predict_proba(X_all)[:,1]\n\n# ROC-AUC\nroc_auc_cat = roc_auc_score(y_all, y_proba_cat)\nprint(f\"ROC AUC Score (Full Dataset): {roc_auc_cat:.5f}\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_all, y_pred)\ncm_df = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],\n                     columns=[f\"Pred_{i}\" for i in range(cm.shape[1])])\nprint(\"Confusion Matrix (Full Dataset):\")\nprint(cm_df)\n</pre> # Full dataset X_all, y_all = Definedata(df2)  # Classification report report = classification_report(y_all, y_pred, digits=4) print(\"=== Classification Report on Full Dataset ===\") print(report)  # Get probabilities for the positive class (Class=1) y_proba_cat = cat_model.predict_proba(X_all)[:,1]  # ROC-AUC roc_auc_cat = roc_auc_score(y_all, y_proba_cat) print(f\"ROC AUC Score (Full Dataset): {roc_auc_cat:.5f}\")  # Confusion Matrix cm = confusion_matrix(y_all, y_pred) cm_df = pd.DataFrame(cm, index=[f\"Actual_{i}\" for i in range(cm.shape[0])],                      columns=[f\"Pred_{i}\" for i in range(cm.shape[1])]) print(\"Confusion Matrix (Full Dataset):\") print(cm_df) <pre>=== Classification Report on Full Dataset ===\n              precision    recall  f1-score   support\n\n           0     1.0000    0.9997    0.9998    284315\n           1     0.8497    1.0000    0.9188       492\n\n    accuracy                         0.9997    284807\n   macro avg     0.9249    0.9998    0.9593    284807\nweighted avg     0.9997    0.9997    0.9997    284807\n\nROC AUC Score (Full Dataset): 0.99998\nConfusion Matrix (Full Dataset):\n          Pred_0  Pred_1\nActual_0  284228      87\nActual_1       0     492\n</pre> <p>Different from other models, this model does not rely too heavily on specific features as the feature importance table showed that 8 most importance features are just accounted for over 50% of the cumulative importance, differ from over 80% model. Besides highly correlated and familiar features, CatBoost surprisingly recognised \u201cTime\u201d, V8, and V26 in the top 7 most important features. This finding shows that CatBoost, though having slightly weaker performance comparing to Random Forest and XGBoost, the score of this model might improve fraudulent transaction prediction as it considers more features. On the other hand, this result leads to the supposition that since this model treats highly correlated features more lightly than other models, its effectiveness is not as strong as Random Forest or XGBoost.</p> In\u00a0[\u00a0]: Copied! <pre># Calculate ROC curve points\nfpr, tpr, thresholds = roc_curve(y_all, y_proba_cat)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_cat:.5f})')\nplt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve - CatBoost', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Calculate ROC curve points fpr, tpr, thresholds = roc_curve(y_all, y_proba_cat)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc_cat:.5f})') plt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve - CatBoost', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show() In\u00a0[\u00a0]: Copied! <pre># Calculate Gini coefficient\ngini_cat = 2 * roc_auc_cat - 1\nprint(f\"Gini Coefficient of CatBoost: {gini_cat:.4f}\")\n</pre> # Calculate Gini coefficient gini_cat = 2 * roc_auc_cat - 1 print(f\"Gini Coefficient of CatBoost: {gini_cat:.4f}\") <pre>Gini Coefficient of CatBoost: 1.0000\n</pre> <p>With this level of prediction, similar to Random Forest and XGBoost, CatBoost has GINI approximately 1.0000 and a highly appreciated predicting performance.</p> In\u00a0[\u00a0]: Copied! <pre># Combine the anomative detection score into the dataframe\ndf_processed = pd.DataFrame(X_scaled, columns=features)\n\n# Combine the machine learning result into the dataframe\ndf_processed['xgb_pred'] = xgb_model.predict_proba(X_all)[:, 1]\ndf_processed['rf_pred']  = rf_model.predict_proba(X_all)[:, 1]\ndf_processed['cat_pred'] = cat_model.predict_proba(X_all)[:, 1]\n</pre> # Combine the anomative detection score into the dataframe df_processed = pd.DataFrame(X_scaled, columns=features)  # Combine the machine learning result into the dataframe df_processed['xgb_pred'] = xgb_model.predict_proba(X_all)[:, 1] df_processed['rf_pred']  = rf_model.predict_proba(X_all)[:, 1] df_processed['cat_pred'] = cat_model.predict_proba(X_all)[:, 1] In\u00a0[\u00a0]: Copied! <pre># Create hybrid features set that include the predict results\nhybrid_features = df_processed[['xgb_pred', 'rf_pred', 'cat_pred']]\n\n# Train meta-classifier (Logistic Regression)\nmeta_model = LogisticRegression()\nmeta_model.fit(hybrid_features, y)\n</pre> # Create hybrid features set that include the predict results hybrid_features = df_processed[['xgb_pred', 'rf_pred', 'cat_pred']]  # Train meta-classifier (Logistic Regression) meta_model = LogisticRegression() meta_model.fit(hybrid_features, y) Out[\u00a0]: <pre>LogisticRegression()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFitted<pre>LogisticRegression()</pre> In\u00a0[\u00a0]: Copied! <pre># Predict probability of class 1 (fraud)\nhybrid_probs = meta_model.predict_proba(hybrid_features)[:, 1]\n</pre> # Predict probability of class 1 (fraud) hybrid_probs = meta_model.predict_proba(hybrid_features)[:, 1] In\u00a0[\u00a0]: Copied! <pre># Find precision, recall v\u00e0 thresholds\nprecision, recall, thresholds = precision_recall_curve(y, hybrid_probs)\n\n# Find F1-score for threshold\nf1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-10)\n\n# Find best threshold\nbest_idx = np.argmax(f1_scores)\nbest_threshold = thresholds[best_idx]\nprint(f\"Best threshold based on F1 for hybrid model: {best_threshold:.4f}\")\n\n# Predict labels by best threshold\nhybrid_pred_labels = (hybrid_probs &gt;= best_threshold).astype(int)\n\n# In classification report\nprint(\"Classification Report\")\nprint(classification_report(y, hybrid_pred_labels, digits=4))\n\n# ROC-AUC\nroc_auc = roc_auc_score(y, hybrid_probs)\nprint(f\"ROC-AUC Score: {roc_auc:.5f}\")\n\n# Plot Precision-Recall Curve\nplt.figure(figsize=(7,5))\nplt.plot(recall, precision, color='green', label='PR Curve')\nplt.scatter(recall[best_idx], precision[best_idx], color='red',\n            label=f'Best Threshold = {best_threshold:.4f}')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Hybrid Model Precision-Recall Curve')\nplt.legend()\nplt.show()\n</pre> # Find precision, recall v\u00e0 thresholds precision, recall, thresholds = precision_recall_curve(y, hybrid_probs)  # Find F1-score for threshold f1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-10)  # Find best threshold best_idx = np.argmax(f1_scores) best_threshold = thresholds[best_idx] print(f\"Best threshold based on F1 for hybrid model: {best_threshold:.4f}\")  # Predict labels by best threshold hybrid_pred_labels = (hybrid_probs &gt;= best_threshold).astype(int)  # In classification report print(\"Classification Report\") print(classification_report(y, hybrid_pred_labels, digits=4))  # ROC-AUC roc_auc = roc_auc_score(y, hybrid_probs) print(f\"ROC-AUC Score: {roc_auc:.5f}\")  # Plot Precision-Recall Curve plt.figure(figsize=(7,5)) plt.plot(recall, precision, color='green', label='PR Curve') plt.scatter(recall[best_idx], precision[best_idx], color='red',             label=f'Best Threshold = {best_threshold:.4f}') plt.xlabel('Recall') plt.ylabel('Precision') plt.title('Hybrid Model Precision-Recall Curve') plt.legend() plt.show() <pre>Best threshold based on F1 for hybrid model: 0.6100\nClassification Report\n              precision    recall  f1-score   support\n\n           0     1.0000    0.9999    1.0000    284315\n           1     0.9609    1.0000    0.9801       492\n\n    accuracy                         0.9999    284807\n   macro avg     0.9805    1.0000    0.9900    284807\nweighted avg     0.9999    0.9999    0.9999    284807\n\nROC-AUC Score: 0.99999\n</pre> In\u00a0[\u00a0]: Copied! <pre># Compute confusion matrix\ncm = confusion_matrix(y, hybrid_pred_labels)\n\n# Plot the confusion matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, cmap=\"icefire\", fmt='g')\n\n# Add labels, title, and axis ticks\nplt.title('Hybrid Model Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.show()\n</pre> # Compute confusion matrix cm = confusion_matrix(y, hybrid_pred_labels)  # Plot the confusion matrix plt.figure(figsize=(6, 4)) sns.heatmap(cm, annot=True, cmap=\"icefire\", fmt='g')  # Add labels, title, and axis ticks plt.title('Hybrid Model Confusion Matrix') plt.xlabel('Predicted') plt.ylabel('Actual') plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.show() In\u00a0[\u00a0]: Copied! <pre># Calculate ROC curve points\nfpr, tpr, thresholds = roc_curve(y_all, hybrid_probs)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc:.5f})')\nplt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve - Hybrid model', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Calculate ROC curve points fpr, tpr, thresholds = roc_curve(y_all, hybrid_probs)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc:.5f})') plt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve - Hybrid model', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show() In\u00a0[\u00a0]: Copied! <pre># Pick a transaction from the dataframe\ntransaction = df.iloc[[105]].iloc[:, :-1]\nprint(transaction)\n</pre> # Pick a transaction from the dataframe transaction = df.iloc[[105]].iloc[:, :-1] print(transaction) <pre>     Time        V1        V2        V3        V4        V5        V6  \\\n105  69.0 -2.220642  1.029181 -0.697724 -1.268226  2.802221  3.322901   \n\n           V7        V8        V9  ...      V20       V21       V22       V23  \\\n105  0.197036 -0.521297  0.859596  ... -0.11153  0.110448 -1.178463  0.508911   \n\n          V24       V25       V26       V27       V28  Amount  \n105  0.923385  0.213759  0.033507 -0.142025 -0.263844    9.47  \n\n[1 rows x 30 columns]\n</pre> In\u00a0[\u00a0]: Copied! <pre>def predict_transaction(transaction, scaler, iso_forest, autoencoder,\n                            xgb_model, rf_model, cat_model, meta_model, best_threshold):\n    # Scale\n    X_scaled_new = scaler.transform(transaction)\n\n    # Anomaly scores\n    iso_score_new = -iso_forest.decision_function(X_scaled_new)[0]\n    reconstruction_new = autoencoder.predict(X_scaled_new)\n    ae_mse_new = np.mean(np.power(X_scaled_new - reconstruction_new, 2))\n\n    # Supervised predictions\n    xgb_pred_new = xgb_model.predict_proba(X_scaled_new)[:, 1][0]\n    rf_pred_new  = rf_model.predict_proba(X_scaled_new)[:, 1][0]\n    cat_pred_new = cat_model.predict_proba(X_scaled_new)[:, 1][0]\n\n    # Hybrid vector\n    hybrid_vector_new = np.array([[iso_score_new, ae_mse_new, xgb_pred_new, rf_pred_new, cat_pred_new]])\n\n    # Meta model prediction\n    prob_new = meta_model.predict_proba(hybrid_vector_new)[:, 1][0]\n    label_new = int(prob_new &gt;= best_threshold)\n\n    return {\n        \"iso_score\": iso_score_new,\n        \"ae_mse\": ae_mse_new,\n        \"xgb_pred\": xgb_pred_new,\n        \"rf_pred\": rf_pred_new,\n        \"cat_pred\": cat_pred_new,\n        \"hybrid_prob\": prob_new,\n        \"predicted_label\": label_new,\n        \"result\": \"FRAUD\" if label_new==1 else \"NON-FRAUD\"\n    }\n\n# Usage\nresult = predict_transaction(transaction, scaler, iso_forest, autoencoder,\n                                 xgb_model, rf_model, cat_model, meta_model, best_threshold)\n\nprint(result)\n</pre> def predict_transaction(transaction, scaler, iso_forest, autoencoder,                             xgb_model, rf_model, cat_model, meta_model, best_threshold):     # Scale     X_scaled_new = scaler.transform(transaction)      # Anomaly scores     iso_score_new = -iso_forest.decision_function(X_scaled_new)[0]     reconstruction_new = autoencoder.predict(X_scaled_new)     ae_mse_new = np.mean(np.power(X_scaled_new - reconstruction_new, 2))      # Supervised predictions     xgb_pred_new = xgb_model.predict_proba(X_scaled_new)[:, 1][0]     rf_pred_new  = rf_model.predict_proba(X_scaled_new)[:, 1][0]     cat_pred_new = cat_model.predict_proba(X_scaled_new)[:, 1][0]      # Hybrid vector     hybrid_vector_new = np.array([[iso_score_new, ae_mse_new, xgb_pred_new, rf_pred_new, cat_pred_new]])      # Meta model prediction     prob_new = meta_model.predict_proba(hybrid_vector_new)[:, 1][0]     label_new = int(prob_new &gt;= best_threshold)      return {         \"iso_score\": iso_score_new,         \"ae_mse\": ae_mse_new,         \"xgb_pred\": xgb_pred_new,         \"rf_pred\": rf_pred_new,         \"cat_pred\": cat_pred_new,         \"hybrid_prob\": prob_new,         \"predicted_label\": label_new,         \"result\": \"FRAUD\" if label_new==1 else \"NON-FRAUD\"     }  # Usage result = predict_transaction(transaction, scaler, iso_forest, autoencoder,                                  xgb_model, rf_model, cat_model, meta_model, best_threshold)  print(result) <pre>1/1 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 80ms/step\n{'iso_score': np.float64(0.007253403387947666), 'ae_mse': np.float64(0.04523819418918071), 'xgb_pred': np.float32(1.8195233e-06), 'rf_pred': np.float64(0.01), 'cat_pred': np.float64(0.00020015775559480717), 'hybrid_prob': np.float64(4.871344216687655e-05), 'predicted_label': 0, 'result': 'NON-FRAUD'}\n</pre> In\u00a0[\u00a0]: Copied! <pre># Use output from Isolation Forest\niso_imp_scores = - iso_forest_imp.decision_function(Z_scaled)\n\n# Calculate reconstruction error for all transactions\nreconstructed_imp = autoencoder_imp.predict(Z_scaled)\nae_mse_imp = np.mean(np.power(Z_scaled - reconstructed_imp, 2), axis=1)\n</pre> # Use output from Isolation Forest iso_imp_scores = - iso_forest_imp.decision_function(Z_scaled)  # Calculate reconstruction error for all transactions reconstructed_imp = autoencoder_imp.predict(Z_scaled) ae_mse_imp = np.mean(np.power(Z_scaled - reconstructed_imp, 2), axis=1) <pre>8901/8901 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 21s 2ms/step\n</pre> In\u00a0[\u00a0]: Copied! <pre># Combine the anomative detection score into the dataframe\ndf_imp_processed = pd.DataFrame(X_scaled, columns=features)\ndf_imp_processed['iso_imp_score'] = iso_imp_scores\ndf_imp_processed['ae_mse_imp'] = ae_mse_imp\n\n# Combine the machine learning result into the dataframe\ndf_imp_processed['xgb_pred'] = xgb_model.predict_proba(X_all)[:, 1]\ndf_imp_processed['rf_pred']  = rf_model.predict_proba(X_all)[:, 1]\ndf_imp_processed['cat_pred'] = cat_model.predict_proba(X_all)[:, 1]\n</pre> # Combine the anomative detection score into the dataframe df_imp_processed = pd.DataFrame(X_scaled, columns=features) df_imp_processed['iso_imp_score'] = iso_imp_scores df_imp_processed['ae_mse_imp'] = ae_mse_imp  # Combine the machine learning result into the dataframe df_imp_processed['xgb_pred'] = xgb_model.predict_proba(X_all)[:, 1] df_imp_processed['rf_pred']  = rf_model.predict_proba(X_all)[:, 1] df_imp_processed['cat_pred'] = cat_model.predict_proba(X_all)[:, 1] In\u00a0[\u00a0]: Copied! <pre>df_imp_processed.head()\n</pre> df_imp_processed.head() Out[\u00a0]: Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V25 V26 V27 V28 Amount iso_imp_score ae_mse_imp xgb_pred rf_pred cat_pred 0 0.000000 0.603329 0.568680 0.827359 0.313023 0.534965 0.483822 0.466600 0.598640 0.475312 ... 0.585122 0.394557 0.494419 0.437517 0.493873 -0.096648 0.008200 2.593828e-05 0.00 0.009689 1 0.000000 0.913978 0.609850 0.649577 0.271796 0.576993 0.423477 0.432795 0.596946 0.453981 ... 0.587290 0.446013 0.474206 0.443100 0.128583 -0.125139 0.004869 8.898125e-05 0.00 0.000217 2 0.000006 0.603445 0.463820 0.788393 0.268766 0.521003 0.569201 0.509432 0.615936 0.410603 ... 0.559515 0.402727 0.467443 0.431659 0.584923 -0.047575 0.012505 3.374158e-06 0.00 0.000536 3 0.000006 0.637817 0.555279 0.789533 0.213661 0.568756 0.540277 0.466414 0.629394 0.414999 ... 0.614245 0.389197 0.484707 0.450191 0.475117 -0.081274 0.008289 6.509570e-07 0.00 0.000034 4 0.000012 0.620208 0.662831 0.774862 0.269796 0.528934 0.445914 0.495771 0.553269 0.490950 ... 0.566343 0.507497 0.505407 0.471486 0.419792 -0.107677 0.008037 1.668062e-07 0.01 0.001001 <p>5 rows \u00d7 35 columns</p> In\u00a0[\u00a0]: Copied! <pre># Create hybrid features set that include the predict results\nhybrid_imp_features = df_imp_processed[['iso_imp_score', 'ae_mse_imp', 'xgb_pred', 'rf_pred','cat_pred']]\n\n# Train meta-classifier (Logistic Regression)\nmeta_imp_model = LogisticRegression()\nmeta_imp_model.fit(hybrid_imp_features, y)\n</pre> # Create hybrid features set that include the predict results hybrid_imp_features = df_imp_processed[['iso_imp_score', 'ae_mse_imp', 'xgb_pred', 'rf_pred','cat_pred']]  # Train meta-classifier (Logistic Regression) meta_imp_model = LogisticRegression() meta_imp_model.fit(hybrid_imp_features, y) Out[\u00a0]: <pre>LogisticRegression()</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFitted<pre>LogisticRegression()</pre> In\u00a0[\u00a0]: Copied! <pre># Predict probability of class 1 (fraud)\nhybrid_imp_probs = meta_imp_model.predict_proba(hybrid_imp_features)[:, 1]\n</pre> # Predict probability of class 1 (fraud) hybrid_imp_probs = meta_imp_model.predict_proba(hybrid_imp_features)[:, 1] In\u00a0[\u00a0]: Copied! <pre># Find precision, recall v\u00e0 thresholds\nprecision, recall, thresholds = precision_recall_curve(y, hybrid_imp_probs)\n\n# Find F1-score for threshold\nf1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-10)\n\n# Find best threshold\nbest_idx = np.argmax(f1_scores)\nbest_threshold = thresholds[best_idx]\nprint(f\"Best threshold based on F1 for hybrid model: {best_threshold:.4f}\")\n\n# Predict labels by best threshold\nhybrid_imp_pred_labels = (hybrid_imp_probs &gt;= best_threshold).astype(int)\n\n# In classification report\nprint(\"Classification Report\")\nprint(classification_report(y, hybrid_imp_pred_labels, digits=4))\n\n# ROC-AUC\nroc_auc_hybrid_imp = roc_auc_score(y, hybrid_imp_probs)\nprint(f\"ROC-AUC Score: {roc_auc_hybrid_imp:.5f}\")\n\n# Plot Precision-Recall Curve\nplt.figure(figsize=(7,5))\nplt.plot(recall, precision, color='green', label='PR Curve')\nplt.scatter(recall[best_idx], precision[best_idx], color='red',\n            label=f'Best Threshold = {best_threshold:.4f}')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Hybrid Model Precision-Recall Curve (High-corelated Features)')\nplt.legend()\nplt.show()\n</pre> # Find precision, recall v\u00e0 thresholds precision, recall, thresholds = precision_recall_curve(y, hybrid_imp_probs)  # Find F1-score for threshold f1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-10)  # Find best threshold best_idx = np.argmax(f1_scores) best_threshold = thresholds[best_idx] print(f\"Best threshold based on F1 for hybrid model: {best_threshold:.4f}\")  # Predict labels by best threshold hybrid_imp_pred_labels = (hybrid_imp_probs &gt;= best_threshold).astype(int)  # In classification report print(\"Classification Report\") print(classification_report(y, hybrid_imp_pred_labels, digits=4))  # ROC-AUC roc_auc_hybrid_imp = roc_auc_score(y, hybrid_imp_probs) print(f\"ROC-AUC Score: {roc_auc_hybrid_imp:.5f}\")  # Plot Precision-Recall Curve plt.figure(figsize=(7,5)) plt.plot(recall, precision, color='green', label='PR Curve') plt.scatter(recall[best_idx], precision[best_idx], color='red',             label=f'Best Threshold = {best_threshold:.4f}') plt.xlabel('Recall') plt.ylabel('Precision') plt.title('Hybrid Model Precision-Recall Curve (High-corelated Features)') plt.legend() plt.show() <pre>Best threshold based on F1 for hybrid model: 0.5970\n=== Classification Report ===\n              precision    recall  f1-score   support\n\n           0     1.0000    0.9999    1.0000    284315\n           1     0.9609    1.0000    0.9801       492\n\n    accuracy                         0.9999    284807\n   macro avg     0.9805    1.0000    0.9900    284807\nweighted avg     0.9999    0.9999    0.9999    284807\n\nROC-AUC Score: 0.99999\n</pre> In\u00a0[\u00a0]: Copied! <pre># Compute confusion matrix\ncm = confusion_matrix(y, hybrid_imp_pred_labels)\n\n# Plot the confusion matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, cmap=\"icefire\", fmt='g')\n\n# Add labels, title, and axis ticks\nplt.title('Hybrid Model 2 Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)'])\nplt.show()\n</pre> # Compute confusion matrix cm = confusion_matrix(y, hybrid_imp_pred_labels)  # Plot the confusion matrix plt.figure(figsize=(6, 4)) sns.heatmap(cm, annot=True, cmap=\"icefire\", fmt='g')  # Add labels, title, and axis ticks plt.title('Hybrid Model 2 Confusion Matrix') plt.xlabel('Predicted') plt.ylabel('Actual') plt.xticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.yticks([0.5, 1.5], ['Non-Fraud (0)', 'Fraud (1)']) plt.show() In\u00a0[\u00a0]: Copied! <pre># Calculate ROC curve points\nfpr, tpr, thresholds = roc_curve(y_all, hybrid_imp_pred_labels)\n\n# Plot ROC curve\nplt.figure(figsize=(7, 5))\nplt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc:.5f})')\nplt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC Curve - Hybrid model (High-correlated Features)', fontsize=14, fontweight='bold')\nplt.legend(loc='lower right')\nplt.grid(alpha=0.3)\nplt.show()\n</pre> # Calculate ROC curve points fpr, tpr, thresholds = roc_curve(y_all, hybrid_imp_pred_labels)  # Plot ROC curve plt.figure(figsize=(7, 5)) plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (AUC = {roc_auc:.5f})') plt.plot([0,1], [0,1], color='navy', linestyle='--', label='Random guess') plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel('False Positive Rate', fontsize=12) plt.ylabel('True Positive Rate', fontsize=12) plt.title('ROC Curve - Hybrid model (High-correlated Features)', fontsize=14, fontweight='bold') plt.legend(loc='lower right') plt.grid(alpha=0.3) plt.show()"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#machine-learning-models","title":"Machine Learning Models\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#1-library-importing","title":"1. Library importing\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#3-unsupervised-learning","title":"3. Unsupervised Learning\u00b6","text":"<p>To explore performance of unsupervised learning methods, the project tests the performance of four different unsupervised methods, including Isolation Forest, One Class SVM, Local Outlier Factor, and Autoencoder.</p> <ul> <li>Isolation Forest: This technique works by randomly selecting features and splitting data points. Anomalies, or outliers, are easier to isolate, resulting in shorter paths in the \"forest.\" It's effective for large datasets, as it can quickly identify anomalies without needing to model the data's distribution. However, it may miss complex patterns since it relies on simple random splits.</li> <li>One Class SVM: This model learns the boundary of normal data points and flags any points outside this boundary as anomalies. It's particularly powerful in high-dimensional spaces where traditional methods may struggle. However, it can be computationally intensive and sensitive to the presence of noise in the data, which can lead to misclassification.</li> <li>Local Outlier Factor (LOF): LOF assesses the local density of each data point compared to its neighbours. If a point has a significantly lower density than those around it, it's considered an outlier. This technique is useful for identifying anomalies in varying densities, but it can be sensitive to the choice of the number of neighbours, which affects its performance.</li> <li>Autoencoder: These are neural networks designed to compress and reconstruct data. By training on normal transactions, they learn to recreate them effectively. If a transaction cannot be reconstructed well, it's flagged as an anomaly. Autoencoders are great for capturing complex patterns in data, but they require more computational resources and careful tuning of architecture and parameters to perform effectively. In this Appendix 3, the project provides further discuss related to the performance of each unsupervised learning methods when using full original dataset and the high-correlated one, which include 11 variables that have correlation with \u2018Class\u2019 \u2265 0.1 as mentioned before.</li> </ul>"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#31-feature-transformation","title":"3.1. Feature transformation\u00b6","text":"<p>Feature transformation plays an essential role in anomaly detection. Many anomaly detection techniques work best when the data follows a Gaussian (normal) distribution. If our features are skewed (i.e., they have long tails in one direction) or are on different scales, these algorithms may struggle to accurately identify normal data points and anomalies. This could lead to normal instances being wrongly flagged as outliers or genuine anomalies being overlooked.</p> <p>According to our histogram plots, many of our features are highly skewed. To address this issue, we will apply log transformations; therefore, we will stabilize variance, reduce skewness, and enhance the interpretability of the data. This ensures that the characteristics of the data align more closely with the assumptions of the model, thereby improving its ability to accurately identify anomalies and enhancing the overall reliability of the detection process.</p>"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#32-isolation-forest","title":"3.2. Isolation Forest\u00b6","text":"<p>This technique works by randomly selecting features and splitting data points. Anomalies, or outliers, are easier to isolate, resulting in shorter paths in the \"forest.\" It's effective for large datasets, as it can quickly identify anomalies without needing to model the data's distribution. However, it may miss complex patterns since it relies on simple random splits.</p>"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#33-one-class-svm","title":"3.3. One Class SVM\u00b6","text":"<p>One Class SVM showed slightly better performance than Isolation Forest, but it takes too much time to conduct for a large dataset. This disadvantage makes this approach not suitable for real-life applications or applying to hybrid models.</p>"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#34-local-outlier-factor-lof","title":"3.4. Local Outlier Factor (LOF)\u00b6","text":"<p>LOF assesses the local density of each data point compared to its neighbors. If a point has a significantly lower density than those around it, it's considered an outlier. This technique is useful for identifying anomalies in varying densities but can be sensitive to the choice of the number of neighbors, which affects its performance.</p>"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#35-autoencoders","title":"3.5. Autoencoders\u00b6","text":"<p>These are neural networks designed to compress and reconstruct data. By training on normal transactions, they learn to recreate them effectively. If a transaction cannot be reconstructed well, it's flagged as an anomaly. Autoencoders are great for capturing complex patterns in data, but they require more computational resources and careful tuning of architecture and parameters to perform effectively.</p>"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#4-anomaly-detection-with-high-correlated-features","title":"4. Anomaly Detection with High-correlated features\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#41-data-preparation-high-correlated-set","title":"4.1. Data preparation (High-correlated set)\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#42-isolation-forest-with-high-correlated-variables","title":"4.2. Isolation Forest with High-correlated variables\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#43-autoencoder-with-high-correlatd-variables","title":"4.3. Autoencoder with High-correlatd variables\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#summary","title":"Summary\u00b6","text":"<p>The project tested the fraud detection effectiveness of five different unsupervised learning algorithms. The outcomes show that Isolation Forest and One Class SVM demonstrated the highest accuracy rates in identifying fraudulent activity, followed by Autoencoder. Specifically, Isolation Forest performed well overall, achieving high recall (0.8516) for fraudulent cases and strong overall accuracy (0.9512). This indicates that it correctly detected most fraud while maintaining a good balance across classes. One-class SVM shows similar patterns recall but having a slightly worse performance; furthermore, its time-consuming nature may limit its practical application in real-time fraud detection systems. Autoencoders showed a strong balance between recall (0.8943) and accuracy (0.90). Despite its low precision (0.0154), its ability to capture most frauds makes it suitable and worthwhile for trade off, since it is often better to flag more potential cases for review than to miss real frauds. Local Outlier Factor, although the theory seems promising, its practical performance is worse with low precision, recall, and F1-score for fraud transactions (0.0025, 0.0711, and 0.0048, respectively). In summary, the results indicate that Isolation Forest and the Autoencoder are the most real-life applicable unsupervised models for fraud detection. The project further analysed the application of these 2 effective unsupervised learning algorithms by testing only on features with absolute correlations with \u2018Class\u2019 \u2265 0.1. The result shows that removing weak variables can reduce noise and allow the models to focus on the most relevant patterns and improve the accuracy of Isolation Forest and Autoencoder. As shown in Table X, both models achieved higher recall for fraudulent transactions, increasing from 0.8516 to 0.8963 for Isolation Forest and from 0.8943 to 0.9085 for the Autoencoder. This means the models were able to detect a larger proportion of actual fraud cases after weak features were excluded. The F1-scores for the fraud class also improved slightly for Isolation Forest, reflecting a better balance between identifying frauds and limiting the number of false positives. These results suggest that using unsupervised learning on higher correlation features further enhances the models\u2019 sensitivity to meaningful anomalies, leading to stronger and more efficient unsupervised fraud detection performance.</p>"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#5-machine-learning","title":"5. Machine Learning\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#51-data-preposessing-with-smote","title":"5.1. Data preposessing with SMOTE\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#52-random-forest","title":"5.2. Random Forest\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#53-xgboost","title":"5.3. XGBoost\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#55-catboost-classifier","title":"5.5. CatBoost Classifier\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#6-hybrid-model","title":"6. Hybrid model\u00b6","text":"<p>Overall: Hybrid models that integrate both supervised and unsupervised learning methods were built and showed a better result in fraud detection for this data frame (Shanaa M and Abdallah M, 2025; Tayab). Under the scope of this project, the chosen methods include Isolation Forest, Autoencoder for unsupervised learning, and Random Forest, XGBoost, and CatBoost for supervised learning. Supervised algorithms, such as Random Forest and XGBoost, are used to learn from labelled data and recognize known fraud patterns, while unsupervised algorithms like Isolation Forest and Autoencoder detect abnormal or unseen behaviours through anomaly and reconstruction error analysis. The outputs of these models are then combined and fed into a Logistic Regression meta-classifier, which learns the optimal balance between them. This hybrid approach enhances adaptability, precision, and robustness, enabling the system to detect both historical and emerging fraud effectively. Since fraud detection performed better on a modified data frame with highly correlated variables, the project also tested Hybrid Model 2 using unsupervised method scores from this data frame. The result shows that this approach can increase accuracy, lower the false positive rate, increase the F1-score (0) to 1.00, and the F1-score (1) to 0.9801 with only 20 false positives. Hybrid Model 1 and 2 have the same performance, just different thresholds (0.6100 and 0.5970).</p>"},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#61-hybrid-model-with-full-dataset","title":"6.1. Hybrid model with full dataset\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#62-example-of-predicting-a-transaction-with-this-model","title":"6.2. Example of predicting a transaction with this model\u00b6","text":""},{"location":"notebooks/Models_Risk_Analytics_PLA_Credit_Card_Fraud_2/#63-hybrid-model-inputs-from-applying-unsupervised-methods-with-only-high-correlated-features","title":"6.3. Hybrid model inputs from applying Unsupervised methods with only high correlated features\u00b6","text":""}]}